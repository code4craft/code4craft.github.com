<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[代码人生]]></title>
  <link href="http://code4craft.github.com/atom.xml" rel="self"/>
  <link href="http://code4craft.github.com/"/>
  <updated>2013-10-20T16:29:56+08:00</updated>
  <id>http://code4craft.github.com/</id>
  <author>
    <name><![CDATA[黄亿华]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[MockSocks开发日志之三-为NIO设置Socks代理]]></title>
    <link href="http://code4craft.github.com/blog/2013/10/20/mocksockskai-fa-ri-zhi-zhi-san-wei-nioshe-zhi-socksdai-li/"/>
    <updated>2013-10-20T16:28:00+08:00</updated>
    <id>http://code4craft.github.com/blog/2013/10/20/mocksockskai-fa-ri-zhi-zhi-san-wei-nioshe-zhi-socksdai-li</id>
    <content type="html"><![CDATA[<h2>回顾</h2>

<p>时隔3个月，MockSocks终于又能继续开发了。这个项目是目前为止做过的最有技术挑战的一个，目标是做成一个后端应用的fiddler，可以监控应用对外的网络流量、分析协议、重定向、并针对每个协议进行修改，同时可以录制和回放。项目也得到了部门总监和其他leader的肯定，可以多花心思弄弄好。</p>

<p>因为项目的核心是一个Socks代理，通过这个代理捕获双方的流量，并进行继续的操作。</p>

<!---more--->


<h2>Server</h2>

<p>Socks Server方面使用netty构建了一个，原本觉得无比复杂的东西，借助netty倒是变得很简单了，具体实现方式在这篇博客：<a href="http://my.oschina.net/flashsword/blog/169361">http://my.oschina.net/flashsword/blog/169361</a>。学习netty期间用心写了几篇文章，也结交了一些朋友，倒是挺开心的。可惜netty系列文章没有完成，估计要等我MockSocks开发完才能继续了。</p>

<h2>配置Client</h2>

<p>server端开发完后，就轮到client端了。JDK的OIO是支持全局代理的，只需在JVM参数中配置<code>-DsocksProxyHost=xxx -DsocksProxyPort=xxx</code>即可。遗憾的是，这个配置对NIO是不起作用的。</p>

<p>后来考虑过几种办法：</p>

<ol>
<li><p>因为公司项目用到NIO的部分，主要也是通过netty做的。那么改netty的API，使其支持代理，是最简单的做法。使用netty构建一个socks client也是得心应手。但是这种做法不够彻底，且不具有通用性。</p></li>
<li><p>修改NIO的接口SocketChannel.open()的实现，使其返回一个可以使用代理的SocketChannel。这种方法最彻底，但是涉及到JDK一些底层API，有些还没有暴露出来，实现难度有点大。</p></li>
</ol>


<p>后来决定采用方法2，顺便学习一下。</p>

<p><code>SelectorProviderImpl</code>、<code>SocketChannelImpl</code>都是VM的私有API，只有下载JDK源码才能看到。下载openjdk源码后，在<code>jdk/src/share/classes/</code>目录可找到。</p>

<p><code>SelectorProvider.provider()</code>是JDK自己的一个扩展点，会根据不同的OS选择不同的SelectorProvider，OSX是KQueue。尝试自己写了一个SocketChannel的子类，做一个全局代理，结果被SelectorImpl摆了一道，里面要求必须实现<code>sun.nio.ch.SelChImpl</code>接口，而这个接口是包级可见的。</p>

<p>抱着侥幸心理，尝试将自己的新类写到<code>sun.nio.ch</code>包下，结果编译通过，加载提示无法访问其父类接口<code>sun.nio.ch.SelChImpl</code>，看来sun对自家的包是做了一些保留的。</p>

<p>后来沮丧的发现，agent的<code>ClassFileTransformer</code>无法获取到系统级别的class，但是看ByteMan介绍，它倒是可以做到，有必要研究一番。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[今天把mou整崩溃了]]></title>
    <link href="http://code4craft.github.com/blog/2013/09/24/jin-tian-ba-mouzheng-beng-kui-liao/"/>
    <updated>2013-09-24T20:17:00+08:00</updated>
    <id>http://code4craft.github.com/blog/2013/09/24/jin-tian-ba-mouzheng-beng-kui-liao</id>
    <content type="html"><![CDATA[<p>一直觉得Mou写markdown，小巧灵活，久而久之也喜欢把一些临时文本放在里面。</p>

<p>结果晚上回来的时候打不开了，内存飙到1.6G，CPU跑到200%多，死活打不开。作为markdown重度患者，简直要崩溃了。</p>

<!---more--->


<p>怀疑是打开了非法的文件导致。删了App重新装，问题依旧，不知道是把临时文件存在哪的。用进程管理器找到打开的文件，将疑似缓存的文件都删了(<code>~/Library</code>下面几个)，依然没有用！</p>

<p>后来都要绝望的时候，竟然蹦出来了，原来是之前随便贴了一些数据，估计是有markdown的保留字，导致Mou解析出错了！下次还是不要乱拷数据到Mou里了吧！</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[名词王国里的新政-解读Java8之lambda表达式]]></title>
    <link href="http://code4craft.github.com/blog/2013/09/15/ming-ci-wang-guo-li-de-xin-zheng-jie-du-java8zhi-lambdabiao-da-shi/"/>
    <updated>2013-09-15T08:36:00+08:00</updated>
    <id>http://code4craft.github.com/blog/2013/09/15/ming-ci-wang-guo-li-de-xin-zheng-jie-du-java8zhi-lambdabiao-da-shi</id>
    <content type="html"><![CDATA[<p>前几天在reddit上看到Java8 M8 Developer Preview版本已经发布了，不免想要尝鲜一把。Developer Preview版本已经所有Feature都完成了，Java8的特性可以在这里看到<a href="http://openjdk.java.net/projects/jdk8/features">http://openjdk.java.net/projects/jdk8/features</a>，下载地址：<a href="http://jdk8.java.net/download.html">http://jdk8.java.net/download.html</a>。</p>

<!--more-->


<h2>下载及配置</h2>

<p>Intellij IDEA已经完美支持Java8了。首先打开Project Structure，在Project里设置新的JDK路径，并设置Modules=>Source=>Language Level为8.0即可。</p>

<p>现在我们可以使用Java8编写程序了！但是当我们开开心心编写完，享受到高级的lambda表达式后，运行程序，会提示：<code>java: Compilation failed: internal java compiler error</code>！这是因为javacc的版本还不对，在Compiler=>Java Compiler里将项目对应的javacc版本选为1.8即可。</p>

<p>什么？你说你用Eclipse？好像目前还没有稳定版！想尝鲜的，可以看看这个地址<a href="http://stackoverflow.com/questions/13295275/programming-java-8-in-eclipse">http://stackoverflow.com/questions/13295275/programming-java-8-in-eclipse</a>，大致是先checkout Eclipse JDT的beta java8分支，然后在Eclipse里运行这个项目，从而启动一个支持java8的Eclipse…不过应该难不倒作为geek的你吧！</p>

<h2>体验lambda表达式</h2>

<p>好了，我们开始体验Java8的新特性-lambda表达式吧！现在我们的匿名类可以写成这样子了：</p>

<figure class='code'><figcaption><span>java8中的lambda </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'> <span class="k">new</span> <span class="nf">Thread</span><span class="o">(()</span> <span class="o">-&gt;</span> <span class="o">{</span>
</span><span class='line'>      <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Foo&quot;</span><span class="o">);</span>
</span><span class='line'>  <span class="o">}).</span><span class="na">start</span><span class="o">();</span>
</span></code></pre></td></tr></table></div></figure>


<p>而之前的写法只能是这样子：</p>

<figure class='code'><figcaption><span>以前的java匿名函数 </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'> <span class="k">new</span> <span class="nf">Thread</span><span class="o">(</span><span class="k">new</span> <span class="n">Runnable</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>      <span class="nd">@Override</span>
</span><span class='line'>      <span class="kd">public</span> <span class="kt">void</span> <span class="nf">run</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>          <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Foo&quot;</span><span class="o">);</span>
</span><span class='line'>      <span class="o">}</span>
</span><span class='line'>  <span class="o">}).</span><span class="na">start</span><span class="o">();</span>
</span></code></pre></td></tr></table></div></figure>


<p>这样一看，我们似乎就是匿名类写起来简单了一点啊？而第二种方法，借助便捷的IDE，好像编写效率也没什么差别？博主开始也是这样认为，仔细学习之后，才知道其中的奥妙所在！</p>

<p>这里有一个重要的信息，就是<strong><code>()-&gt;{}</code>这里代表一个函数，而非一个对象。</strong>可能这么说比较抽象，我们还是代码说话吧：</p>

<figure class='code'><figcaption><span>函数作为参数 </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'> <span class="kd">public</span> <span class="kd">class</span> <span class="nc">LambdaTest</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>      <span class="kd">private</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">bar</span><span class="o">(){</span>
</span><span class='line'>          <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;bar&quot;</span><span class="o">);</span>
</span><span class='line'>      <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>      <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>          <span class="k">new</span> <span class="nf">Thread</span><span class="o">(</span><span class="nl">LambdaTest:</span><span class="o">:</span><span class="n">bar</span><span class="o">).</span><span class="na">start</span><span class="o">();</span>
</span><span class='line'>      <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>看懂了么？这里<code>LambdaTest::bar</code>代表一个函数(用C++的同学笑了)，而new Thread(Runnable runnable)的参数，可以接受是一个函数作为参数！</p>

<p>是不是觉得很神奇，颠覆了Java思维？在剖析原理以前，博主暂且卖个关子，我们先来讲讲什么是lambda表达式。</p>

<h2>什么是lambda表达式</h2>

<h3>lambda表达式的由来</h3>

<p>絮叨几句，现代编程语言的lamdba表达式都来自1930年代初，阿隆佐·邱奇(Alonzo Church)提出的λ演算(Lambda calculus)理论。λ演算的核心思想就是“万物皆函数”。一个λ算子即一个函数，其一般形式是<code>λx.x + 2</code>。一个λ算子可以作为另一个λ算子的输入，从而构建一个高阶的函数。λ演算是函数式编程的鼻祖，大名鼎鼎的编程语言Lisp就是基于λ演算而建立。用过Lisp的应该都清楚，它的语法很简单，但是却有包容万物的能力。</p>

<p>可能搞计算机的对邱奇比较陌生，但是提起和邱奇同时代的另外一个人，大家就会觉得如雷贯耳了，那就是阿兰·图灵。邱奇成名的时候，图灵还是个大学生。邱奇和图灵一起发表了邱奇-图灵论题，并分别提出了λ演算和图灵机，加上哥德尔提出的递归函数一起，在理论上确定了什么是可计算性。至于什么是可计算性，其实博主也说不清楚，但是现代所有计算机程序语言，都可以认为是从三种之一发展而来，并与之等价的。仅此一点，其影响深远，可想而知。当年教我们《计算理论》的是一个德高望重的教授，人称宋公，每次讲到那个辉煌的年代，总是要停下来，神情专注的感叹一句：“伟大啊！”想想确实挺伟大，人家图灵大学时候就奠定了现代计算机的基础，而我们那会大概还在打DOTA…</p>

<p>附上大神们的照片，大家感受一下：</p>

<p><img src="http://static.oschina.net/uploads/space/2013/0914/160058_HLj3_190591.png" alt="turing etc." /></p>

<h3>现代编程语言中的lambda表达式</h3>

<p>好了扯远了，神游过了那个伟大的时代，我们继续思考如何编代码做需求吧…</p>

<p>现代语言的lambda表达式，大概具备几个特征(博主自己归纳的，如有不严谨，欢迎指正)：</p>

<ol>
<li>函数可作为输入；</li>
<li>函数可作为输出；</li>
<li>函数可作用在函数上，形成高阶函数。</li>
<li>函数支持lambda格式的定义。</li>
</ol>


<p>其实有了1、2，3也就是顺水推舟的事情，而4其实没有太大的必要性，因为一般语言都有自己的函数定义方式，4仅仅是作为一种补充。当然实现了4的语言，一般都会说：“你看我实现了lambda表达式！”(望向Java8和Python同学)</p>

<h2>在Java8中使用lambda表达式</h2>

<h3>FunctionalInterface</h3>

<p>Java中的lambda无法单独出现，它需要一个接口来盛放。这个接口必须使用@FunctionalInterface作为注解，并且只有一个未实现的方法。等等，什么叫接口中未实现的方法？恭喜你，猜对了！Java8的接口也可以写实现了。是不是觉得Interface和AbstractClass更加傻傻分不清楚了？但是AbstractClass是无法使用@FunctionalInterface注解的，官方的解释是为了防止AbstractClass的构造函数做一些事情，可能会导致一些调用者意料不到的事情发生。</p>

<p>好了，我们来看一点代码，Runnable接口现在变成了这个样子：</p>

<figure class='code'><figcaption><span>Runnable接口新定义 </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'> <span class="nd">@FunctionalInterface</span>
</span><span class='line'>  <span class="kd">public</span> <span class="kd">interface</span> <span class="nc">Runnable</span> <span class="o">{</span>
</span><span class='line'>      <span class="kd">public</span> <span class="kd">abstract</span> <span class="kt">void</span> <span class="nf">run</span><span class="o">();</span>
</span><span class='line'>  <span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>这里我们可以将任意无参数的lambda表达式赋值给Runnable:</p>

<figure class='code'><figcaption><span>向runnable传递闭包 </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'> <span class="n">Runnable</span> <span class="n">runnable</span> <span class="o">=</span> <span class="o">()</span> <span class="o">-&gt;</span> <span class="o">{</span>
</span><span class='line'>      <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Hello lambda!&quot;</span><span class="o">);</span>
</span><span class='line'>  <span class="o">};</span>
</span><span class='line'>  <span class="n">runnable</span><span class="o">.</span><span class="na">run</span><span class="o">();</span>
</span></code></pre></td></tr></table></div></figure>


<p>lambda表达式本质上是一个函数，所以我们还可以用更加神奇的赋值：</p>

<figure class='code'><figcaption><span>向runnable传递闭包 </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'> <span class="kd">public</span> <span class="kd">class</span> <span class="nc">HelloLambda</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>      <span class="kd">private</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">hellolambda</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>          <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Hello lambda!&quot;</span><span class="o">);</span>
</span><span class='line'>      <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>      <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>          <span class="n">Runnable</span> <span class="n">runnable</span> <span class="o">=</span> <span class="nl">HelloLambda:</span><span class="o">:</span><span class="n">hellolambda</span><span class="o">;</span>
</span><span class='line'>          <span class="n">runnable</span><span class="o">.</span><span class="na">run</span><span class="o">();</span>
</span><span class='line'>      <span class="o">}</span>
</span><span class='line'>  <span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>这里看到这里，大家大概明白了，lambda表达式其实只是个幌子，更深层次的含义是：函数在Java里面可以作为一个实体进行表示了。这就意味着，在Java8里，函数既可以作为函数的参数，也可以作为函数的返回值，即具有了lambda演算的所有特性。</p>

<h3>Function系列API</h3>

<p>看到这里，可能大家会有疑问？什么样的函数和什么样的lambda表达式属于同一类型？答案是参数和返回值的类型共同决定函数的类型。例如Runnable的run方法不接受参数，也没有返回值，那么Runnable接口则可以用任意没有参数且没有返回值的函数来赋值。这样概念上来说，Runnable表示的含义就<strong>从一个对象变成了一个方法</strong>。</p>

<p>这一点在Java8中的java.util.function包里的代码得到了验证。以最具有代表性的Function接口为例：</p>

<figure class='code'><figcaption><span>Function接口 </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'> <span class="nd">@FunctionalInterface</span>
</span><span class='line'>  <span class="kd">public</span> <span class="kd">interface</span> <span class="nc">Function</span><span class="o">&lt;</span><span class="n">T</span><span class="o">,</span> <span class="n">R</span><span class="o">&gt;</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>      <span class="n">R</span> <span class="nf">apply</span><span class="o">(</span><span class="n">T</span> <span class="n">t</span><span class="o">);</span>
</span><span class='line'>
</span><span class='line'>  <span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>有了Function，我们可以这样写：</p>

<figure class='code'><figcaption><span>Function接口的赋值 </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'> <span class="n">Function</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">convert</span> <span class="o">=</span> <span class="nl">String:</span><span class="o">:</span><span class="n">valueOf</span><span class="o">;</span>
</span><span class='line'>  <span class="n">String</span> <span class="n">s</span> <span class="o">=</span> <span class="n">convert</span><span class="o">.</span><span class="na">apply</span><span class="o">(</span><span class="mi">1</span><span class="o">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>这个东东是不是很像Javascript中的函数对象？</p>

<p>可惜的是，这里的Function算是个半成品，它只能表示一个有单个参数，并有非void返回值的函数。像System.out.println()这种方法，因为返回值为void，是无法赋值为Function的！</p>

<p>怎么办？java.util.function包提供了一个不那么完美的解决方案：多定义几个FunctionalInterface呗！</p>

<p>于是，在Java8里有了：</p>

<ul>
<li>Supplier: 没有参数，只有返回值的函数</li>
<li>Consumer: 一个参数，返回值为void的函数</li>
<li>BiFunction: 两个参数，一个返回值的函数</li>
<li>BiConsumer: 两个参数，没有返回值的函数</li>
<li>&hellip;</li>
</ul>


<p>对于这些个API，我也没有什么力气吐槽了，反正我也想不出更好的方法…大家趁机，多学几个单词吧，嗯。</p>

<h2>总结：名词王国的新政</h2>

<p>相信很多同学都看过这篇著名的文章：<a href="http://lcwangchao.github.io/%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B/2012/07/02/excution_in_the_kingdom_of_nouns/">名词王国里的死刑</a>。这篇文章吐槽了Java里，动词(方法)在Java里总是要依附于某个名词(对象/类)存在。</p>

<p>现在动词在名词王国终于有了一个身份了。当然这个动词需要先取得一个名词的身份(FunctionInterface)，然后才能名正言顺的幸存下来。好在Oracle国王预先为他们留了一些身份(Function、Consumer、Supplier、BiFunction&hellip;)，所以大多数动词都已经找到了自己的位置。System.out.println(String)现在是Consumer<String>了，String.valueOf(Integer)现在是Function&lt;Integer,String>了，Collection.size()现在是Supplier<Integer>了…。要为一些较长参数的方法获取一个身份，也是挺容易的(定义一个新的FunctionInterface接口)。</p>

<p>我相信这个影响是深远的。例如下面一段代码，可以同一行代码将一个List<Integer>转换成一个List<String>：</p>

<figure class='code'><figcaption><span>List<Integer>转换成List<String> </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'> <span class="n">List</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">strings</span> <span class="o">=</span> <span class="n">intList</span><span class="o">.</span><span class="na">stream</span><span class="o">().</span><span class="na">map</span><span class="o">(</span><span class="nl">String:</span><span class="o">:</span><span class="n">valueOf</span><span class="o">).</span><span class="na">collect</span><span class="o">(</span><span class="n">Collectors</span><span class="o">.&lt;</span><span class="n">String</span><span class="o">&gt;</span><span class="n">toList</span><span class="o">());</span>
</span></code></pre></td></tr></table></div></figure>


<p>当然问题也存在。因为包含了闭包等因素，FunctionInterface的序列化/反序列化会是一个相当复杂的事情。熟悉Java的开发者，也会因为lambda的引入，带来了一些困惑。俗话说活到老学到老，我倒是不介意这个新功能，你说呢？</p>

<p>本系列文章还有余下几部分，敬请期待：</p>

<p><a href="">lambda表达式与闭包</a></p>

<p><a href="">Java8 lambda表达式原理分析</a></p>

<h2>参考文献：</h2>

<ol>
<li><a href="http://blog.sciencenet.cn/blog-414166-628109.html">http://blog.sciencenet.cn/blog-414166-628109.html</a></li>
<li><a href="http://www.global-sci.org/mc/issues/3/no2/freepdf/80s.pdf">http://www.global-sci.org/mc/issues/3/no2/freepdf/80s.pdf</a></li>
<li><a href="http://en.wikipedia.org/wiki/Lambda_calculus">http://en.wikipedia.org/wiki/Lambda_calculus</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[体验到了open-source的魅力]]></title>
    <link href="http://code4craft.github.com/blog/2013/08/18/ti-yan-dao-liao-open-sourcede-mei-li/"/>
    <updated>2013-08-18T21:58:00+08:00</updated>
    <id>http://code4craft.github.com/blog/2013/08/18/ti-yan-dao-liao-open-sourcede-mei-li</id>
    <content type="html"><![CDATA[<p>webmagic从第一个正式版本到现在大概有一个月了，这一个月一直在提交代码，Longest Streak已经达到了25天，打破了开发blackhole时15天的记录了。webmagic确实是我最得意的一个项目，结合了领域经验和编码功底，包括注释和编码都是精雕细琢的。</p>

<!--more-->


<p>webmagic在oschina上推了两次，反响都挺好，读过源码的都说相当不错。webmagic的fork/star比相当高，看来大家都想改改，这也说明确实源码挺容易理解，挺好！一方面也说明功能不是很够，其实这也是以后的一个方向。</p>

<p>周五的时候往sonatype提交了一个JIRA，希望提交到maven中央库，走上了国际化的路线呢！既然国际化了，也就把注释和readme全部改成了英文。虽然完全是体力活，但是本着坚持终归会有回报的想法，还是很认真的去做了。上周开始用番茄工作法来管理时间，周末这两天都完成了6、7个番茄，比平时工作日都要高，看来果然兴趣才是生产力。</p>

<p>最高兴的是，有一个做爬虫的朋友<a href="https://github.com/yuany">@yuany</a>对webmagic很有兴趣，交流之后，决定把他加到webmagic的合作者里来。因为我工作中没有写爬虫，所以能有个经常写爬虫的合作者是相当好的，应该能把webmagic的易用性提高不少的。</p>

<p>后来对他的提交做了merge，好多我以前写的丑的地方还给做了重构，感觉挺开心的。学习、交流、提高，同时能产生有用的代码，这就是我最初的目标了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[工作满两年时候的总结]]></title>
    <link href="http://code4craft.github.com/blog/2013/08/03/sum/"/>
    <updated>2013-08-03T15:15:00+08:00</updated>
    <id>http://code4craft.github.com/blog/2013/08/03/sum</id>
    <content type="html"><![CDATA[<p>最近工作处于低靡状态。公司玩转型，但是也没转出个啥效果。组里转到前端开发了，产品方向不定，至今也没做出个啥玩意来。工作内容缺少挑战性，更多是跟产品形态打交道了。不是很喜欢这个领域。升职的事也说不准，虽然自己只有两年工作经验，但是由于读书太久，岁数却接近30了，有点危机感。</p>

<p>生活上丰富多彩。女儿出生了，开始操心起来了。压力也大了些，要计划买房了。老婆工作不顺利，不过她自己也没太大所谓，随遇而安吧。</p>

<p>业余项目也挺丰富。BlackHoleJ和webmagic有了不少star了，都有了公司级用户，也得到了不少赞扬。</p>

<!--more-->


<p>webmagic反响出乎意料的好，还有用户去建了一个群，有个朋友基于这个做了一个企业级别的抓取工具(带管理后台的)，朋友们都戏称我教主了。能把这些东西分享出来，并得到肯定，这肯定是非常开心的。这个工具还有很多后续工作要做，最近为了它忙的头昏眼花的，孩子都有好多时候是老婆在带。所幸老婆非常认可我的业余爱好，但是自己多少也得学会安排时间了。</p>

<p>从毕业两年来，技术上的进步我自己是满意的，特别是还有能拿得出手的作品。今后的重点应该是深度为主。今年之后的计划是，好好把自己之前挖的几个坑：webmagic、MonkeySocks和taijicaptcha搞搞，都是有市场有挑战的东西。</p>

<p>另一方面，好好学学与人交往。必须要克服一下了，不然以后的职业发展不好走。</p>

<p>以一个健康的节奏生活并工作下去。</p>

<p>顺便写一下，发布octopress的时候提示：</p>

<pre><code>(&lt;unknown&gt;): did not find expected key while parsing a block mapping at line 2 column 1 in /Users/yihua/codecraft/pages/code4craft/source/_posts/2013-08-03-sum.markdown
</code></pre>

<p>结果是title里面，用到了四个&#8221;&ldquo;&rdquo;&ldquo;。改为&rdquo;&ldquo;之后，generate通过！</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[webmagic的设计机制及原理-如何开发一个Java爬虫]]></title>
    <link href="http://code4craft.github.com/blog/2013/07/18/webmagicde-she-ji-ji-zhi-ji-yuan-li/"/>
    <updated>2013-07-18T14:52:00+08:00</updated>
    <id>http://code4craft.github.com/blog/2013/07/18/webmagicde-she-ji-ji-zhi-ji-yuan-li</id>
    <content type="html"><![CDATA[<p><img src="http://code4craft.github.io/images/posts/spider.jpeg" alt="image" /></p>

<p>之前就有网友在博客里留言，觉得webmagic的实现比较有意思，想要借此研究一下爬虫。最近终于集中精力，花了三天时间，终于写完了这篇文章。之前垂直爬虫写了一年多，webmagic框架写了一个多月，这方面倒是有一些心得，希望对读者有帮助。</p>

<h2>webmagic的目标</h2>

<p>一般来说，一个爬虫包括几个部分：</p>

<ul>
<li><p>页面下载</p>

<p> 页面下载是一个爬虫的基础。下载页面之后才能进行其他后续操作。</p></li>
<li><p>链接提取</p>

<p> 一般爬虫都会有一些初始的种子URL，但是这些URL对于爬虫是远远不够的。爬虫在爬页面的时候，需要不断发现新的链接。</p></li>
<li><p>URL管理</p>

<p> 最基础的URL管理，就是对已经爬过的URL和没有爬的URL做区分，防止重复爬取。</p></li>
<li><p>内容分析和持久化</p>

<p> 一般来说，我们最终需要的都不是原始的HTML页面。我们需要对爬到的页面进行分析，转化成结构化的数据，并存储下来。</p></li>
</ul>


<p>不同的爬虫，对这几部分的要求是不一样的。</p>

<!--more-->


<p>对于通用型的爬虫，例如搜索引擎蜘蛛，需要指对互联网大部分网页无差别进行抓取。这时候难点就在于页面下载和链接管理上&mdash;如果要高效的抓取更多页面，就必须进行更快的下载；同时随着链接数量的增多，需要考虑如果对大规模的链接进行去重和调度，就成了一个很大的问题。一般这些问题都会在大公司有专门的团队去解决，比如这里有一篇来自淘宝的<a href="http://www.searchtb.com/2011/07/%E5%BF%AB%E9%80%9F%E6%9E%84%E5%BB%BA%E5%AE%9E%E6%97%B6%E6%8A%93%E5%8F%96%E9%9B%86%E7%BE%A4.html?spm=0.0.0.0.hHzGxv">快速构建实时抓取集群</a>。</p>

<p>而垂直类型的爬虫要解决的问题则不一样，比如想要爬取一些网站的新闻、博客信息，一般抓取数量要求不是很大，难点则在于如何高效的定制一个爬虫，可以精确的抽取出网页的内容，并保存成结构化的数据。这方面需求很多，webmagic就是为了解决这个目的而开发的。</p>

<p>使用Java语言开发爬虫是比较复杂的。虽然Java有很强大的页面下载、HTML分析工具，但是每个都有不小的学习成本，而且这些工具本身都不是专门为爬虫而生，使用起来也没有那么顺手。我曾经有一年的时间都在开发爬虫，重复的开发让人头痛。Java还有一个比较成熟的框架<a href="https://code.google.com/p/crawler4j/"><strong>crawler4j</strong></a>，但是它是为通用爬虫而设计的，扩展性差一些，满足不了我的业务需要。我也有过自己开发框架的念头，但是终归觉得抽象的不是很好。直到发现python的爬虫框架<a href="http://scrapy.org/"><strong>scrapy</strong></a>，它将爬虫的生命周期拆分的非常清晰，我参照它进行了模块划分，并用Java的方式去实现了它，于是就有了webmagic。</p>

<p>代码已经托管到github，地址是<a href="https://github.com/code4craft/webmagic">https://github.com/code4craft/webmagic</a>，Javadoc：<a href="http://code4craft.github.io/webmagic/docs/">http://code4craft.github.io/webmagic/docs/</a></p>

<p>webmagic的实现还参考了另一个Java爬虫<a href="https://gitcafe.com/laiweiwei/Spiderman"><strong>SpiderMan</strong></a>。SpiderMan是一个全栈式的Java爬虫，它的设计思想跟webmagic稍有不同，它希望将Java语言的实现隔离，仅仅让用户通过配置就完成一个垂直爬虫。理论上，SpiderMan功能更强大，很多功能已经内置，而webmagic则比较灵活，适合熟悉Java语法的开发者，可以比较非常方便的进行扩展和二次开发。</p>

<hr />

<h2>webmagic的模块划分</h2>

<p>webmagic目前的核心代码都在<strong>webmagic-core</strong>中，<strong>webmagic-samples</strong>里有一些定制爬虫的例子，可以作为参考。而<strong>webmagic-plugin</strong>目前还不完善，后期准备加入一些常用的功能。下面主要介绍webmagic-core的内容。</p>

<p>前面说到，webmagic参考了scrapy的模块划分，分为Spider(整个爬虫的调度框架)、Downloader(页面下载)、PageProcessor(链接提取和页面分析)、Scheduler(URL管理)、Pipeline(离线分析和持久化)几部分。只不过scrapy通过middleware实现扩展，而webmagic则通过定义这几个接口，并将其不同的实现注入主框架类Spider来实现扩展。</p>

<p><img src="http://code4craft.github.io/images/posts/webmagic-0.1.0.png" alt="image" /></p>

<h3>Spider类-核心调度</h3>

<p>Spider是爬虫的入口类，Spider的接口调用采用了链式的API设计，其他功能全部通过接口注入Spider实现，下面是启动一个比较复杂的Spider的例子。</p>

<figure class='code'><figcaption><span>启动一个Spider </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'>     <span class="n">Spider</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">sinaBlogProcessor</span><span class="o">)</span>
</span><span class='line'>      <span class="o">.</span><span class="na">scheduler</span><span class="o">(</span><span class="k">new</span> <span class="n">FileCacheQueueScheduler</span><span class="o">(</span><span class="s">&quot;/data/temp/webmagic/cache/&quot;</span><span class="o">))</span>
</span><span class='line'>      <span class="o">.</span><span class="na">pipeline</span><span class="o">(</span><span class="k">new</span> <span class="n">FilePipeline</span><span class="o">())</span>
</span><span class='line'>      <span class="o">.</span><span class="na">thread</span><span class="o">(</span><span class="mi">10</span><span class="o">).</span><span class="na">run</span><span class="o">();</span>  
</span></code></pre></td></tr></table></div></figure>


<p>Spider的核心处理流程非常简单，代码如下：</p>

<figure class='code'><figcaption><span>Spider核心流程 </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'>     <span class="kd">private</span> <span class="kt">void</span> <span class="nf">processRequest</span><span class="o">(</span><span class="n">Request</span> <span class="n">request</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>          <span class="n">Page</span> <span class="n">page</span> <span class="o">=</span> <span class="n">downloader</span><span class="o">.</span><span class="na">download</span><span class="o">(</span><span class="n">request</span><span class="o">,</span> <span class="k">this</span><span class="o">);</span>
</span><span class='line'>          <span class="k">if</span> <span class="o">(</span><span class="n">page</span> <span class="o">==</span> <span class="kc">null</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>              <span class="n">sleep</span><span class="o">(</span><span class="n">site</span><span class="o">.</span><span class="na">getSleepTime</span><span class="o">());</span>
</span><span class='line'>              <span class="k">return</span><span class="o">;</span>
</span><span class='line'>          <span class="o">}</span>
</span><span class='line'>          <span class="n">pageProcessor</span><span class="o">.</span><span class="na">process</span><span class="o">(</span><span class="n">page</span><span class="o">);</span>
</span><span class='line'>          <span class="n">addRequest</span><span class="o">(</span><span class="n">page</span><span class="o">);</span>
</span><span class='line'>          <span class="k">for</span> <span class="o">(</span><span class="n">Pipeline</span> <span class="n">pipeline</span> <span class="o">:</span> <span class="n">pipelines</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>              <span class="n">pipeline</span><span class="o">.</span><span class="na">process</span><span class="o">(</span><span class="n">page</span><span class="o">,</span> <span class="k">this</span><span class="o">);</span>
</span><span class='line'>          <span class="o">}</span>
</span><span class='line'>          <span class="n">sleep</span><span class="o">(</span><span class="n">site</span><span class="o">.</span><span class="na">getSleepTime</span><span class="o">());</span>
</span><span class='line'>      <span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<h3>Downloader-页面下载</h3>

<p>页面下载是一切爬虫的开始。</p>

<p>大部分爬虫都是通过模拟http请求，接收并分析响应来完成。这方面，JDK自带的<strong>HttpURLConnection</strong>可以满足最简单的需要，而<strong>Apache HttpClient</strong>(4.0后整合到HttpCompenent项目中)则是开发复杂爬虫的不二之选。它支持自定义HTTP头(对于爬虫比较有用的就是User-agent、cookie等)、自动redirect、连接复用、cookie保留、设置代理等诸多强大的功能。</p>

<p>webmagic使用了HttpClient 4.2，并封装到了<strong>HttpClientDownloader</strong>。学习HttpClient的使用对于构建高性能爬虫是非常有帮助的，官方的<a href="http://hc.apache.org/httpcomponents-client-ga/tutorial/html/">Tutorial</a>就是很好的学习资料。目前webmagic对HttpClient的使用仍在初步阶段，不过对于一般抓取任务，已经够用了。</p>

<p>下面是一个使用HttpClient最简单的例子：</p>

<figure class='code'><figcaption><span>HttpClient简单使用 </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'>        <span class="n">HttpClient</span> <span class="n">httpClient</span> <span class="o">=</span> <span class="k">new</span> <span class="n">DefaultHttpClient</span><span class="o">();</span>
</span><span class='line'>        <span class="n">HttpGet</span> <span class="n">httpGet</span> <span class="o">=</span> <span class="k">new</span> <span class="n">HttpGet</span><span class="o">(</span><span class="s">&quot;http://youhost/xxx&quot;</span><span class="o">);</span>
</span><span class='line'>        <span class="n">HttpResponse</span> <span class="n">httpResponse</span> <span class="o">=</span> <span class="n">httpClient</span><span class="o">.</span><span class="na">execute</span><span class="o">(</span><span class="n">httpGet</span><span class="o">);</span>
</span><span class='line'>      <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">EntityUtils</span><span class="o">.</span><span class="na">toString</span><span class="o">(</span><span class="n">httpResponse</span><span class="o">.</span><span class="na">getEntity</span><span class="o">().</span><span class="na">getContent</span><span class="o">()));</span>
</span></code></pre></td></tr></table></div></figure>


<p>对于一些Javascript动态加载的网页，仅仅使用http模拟下载工具，并不能取到页面的内容。这方面的思路有两种：一种是抽丝剥茧，分析js的逻辑，再用爬虫去重现它(比如在网页中提取关键数据，再用这些数据去构造Ajax请求，最后直接从响应体获取想要的数据)；
另一种就是：内置一个浏览器，直接获取最后加载完的页面。这方面，js可以使用<strong>PhantomJS</strong>，它内部集成了webkit。而Java可以使用<strong>Selenium</strong>，这是一个非常强大的浏览器模拟工具。考虑以后将它整理成一个独立的Downloader，集成到webmagic中去。</p>

<p>一般没有必要去扩展Downloader。</p>

<h3>PageProcessor-页面分析及链接抽取</h3>

<p>这里说的页面分析主要指HTML页面的分析。页面分析可以说是垂直爬虫最复杂的一部分，在webmagic里，PageProcessor是定制爬虫的核心。通过编写一个实现PageProcessor接口的类，就可以定制一个自己的爬虫。</p>

<p>页面抽取最基本的方式是使用正则表达式。正则表达式好处是非常通用，解析文本的功能也很强大。但是正则表达式最大的问题是，不能真正对HTML进行语法级别的解析，没有办法处理关系到HTML结构的情况(例如处理标签嵌套)。例如，我想要抽取一个&lt;div>里的内容，可以这样写：&#8221;&lt;div>(.*?)&lt;/div>&ldquo;。但是如果这个div内部还包含几个子div，这个时候使用正则表达式就会将子div的&rdquo;&lt;/div>&ldquo;作为终止符截取。为了解决这个问题，我们就需要进行HTML的分析。</p>

<p>HTML分析是一个比较复杂的工作，Java世界主要有几款比较方便的分析工具：</p>

<h4><strong>Jsoup</strong></h4>

<p>Jsoup是一个集强大和便利于一体的HTML解析工具。它方便的地方是，可以用于支持用jquery中css selector的方式选取元素，这对于熟悉js的开发者来说基本没有学习成本。</p>

<figure class='code'><figcaption><span>Jsoup的CSS Selector </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'>     <span class="n">String</span> <span class="n">content</span> <span class="o">=</span> <span class="s">&quot;blabla&quot;</span><span class="o">;</span>
</span><span class='line'>      <span class="n">Document</span> <span class="n">doc</span> <span class="o">=</span> <span class="n">JSoup</span><span class="o">.</span><span class="na">parse</span><span class="o">(</span><span class="n">content</span><span class="o">);</span>
</span><span class='line'>      <span class="n">Elements</span> <span class="n">links</span> <span class="o">=</span> <span class="n">doc</span><span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="s">&quot;a[href]&quot;</span><span class="o">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>Jsoup还支持白名单过滤机制，对于网站防止XSS攻击也是很好的。</p>

<h4><strong>HtmlParser</strong></h4>

<p>HtmlParser的功能比较完备，也挺灵活，但谈不上方便。这个项目很久没有维护了，最新版本是2.1。HtmlParser的核心元素是Node，对应一个HTML标签，支持getChildren()等树状遍历方式。HtmlParser另外一个核心元素是NodeFilter，通过实现NodeFilter接口，可以对页面元素进行筛选。这里有一篇HtmlParser的使用文章：<a href="https://www.ibm.com/developerworks/cn/opensource/os-cn-crawler/">使用 HttpClient 和 HtmlParser 实现简易爬虫</a>。</p>

<h4><strong>Apache tika</strong></h4>

<p>tika是专为抽取而生的工具，还支持PDF、Zip甚至是Java Class。使用tika分析HTML，需要自己定义一个抽取内容的Handler并继承<code>org.xml.sax.helpers.DefaultHandler</code>，解析方式就是xml标准的方式。crawler4j中就使用了tika作为解析工具。SAX这种流式的解析方式对于分析大文件很有用，我个人倒是认为对于解析html意义不是很大。</p>

<figure class='code'><figcaption><span>使用tika进行HTML解析 </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'>     <span class="n">InputStream</span> <span class="n">inputStream</span> <span class="o">=</span> <span class="kc">null</span><span class="o">;</span>
</span><span class='line'>      <span class="n">HtmlParser</span> <span class="n">htmlParser</span> <span class="o">=</span> <span class="k">new</span> <span class="n">HtmlParser</span><span class="o">();</span>
</span><span class='line'>      <span class="n">htmlParser</span><span class="o">.</span><span class="na">parse</span><span class="o">(</span><span class="k">new</span> <span class="n">ByteArrayInputStream</span><span class="o">(</span><span class="n">page</span><span class="o">.</span><span class="na">getContentData</span><span class="o">()),</span>
</span><span class='line'>       <span class="n">contentHandler</span><span class="o">,</span> <span class="n">metadata</span><span class="o">,</span> <span class="k">new</span> <span class="n">ParseContext</span><span class="o">());</span>
</span></code></pre></td></tr></table></div></figure>


<h4><strong>HtmlCleaner与XPath</strong></h4>

<p>HtmlCleaner最大的优点是：支持XPath的方式选取元素。XPath是一门在XML中查找信息的语言，也可以用于抽取HTML元素。XPath与CSS Selector大部分功能都是重合的，但是CSS Selector专门针对HTML，写法更简洁，而XPath则是通用的标准，可以精确到属性值。XPath有一定的学习成本，但是对经常需要编写爬虫的人来说，这点投入绝对是值得的。</p>

<p>学习XPath可以参考w3school的<a href="http://www.w3school.com.cn/xpath/">XPath 教程</a>。下面是使用HtmlCleaner和xpath进行抽取的一段代码：</p>

<figure class='code'><figcaption><span>使用HtmlCleaner和XPath抽取元素 </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'>     <span class="n">HtmlCleaner</span> <span class="n">htmlCleaner</span> <span class="o">=</span> <span class="k">new</span> <span class="n">HtmlCleaner</span><span class="o">();</span>
</span><span class='line'>      <span class="n">TagNode</span> <span class="n">tagNode</span> <span class="o">=</span> <span class="n">htmlCleaner</span><span class="o">.</span><span class="na">clean</span><span class="o">(</span><span class="n">text</span><span class="o">);</span>
</span><span class='line'>      <span class="n">Object</span><span class="o">[]</span> <span class="n">objects</span> <span class="o">=</span> <span class="n">tagNode</span><span class="o">.</span><span class="na">evaluateXPath</span><span class="o">(</span><span class="s">&quot;xpathStr&quot;</span><span class="o">);</span>
</span></code></pre></td></tr></table></div></figure>


<h4>几个工具的对比</h4>

<p>在这里评价这些工具的主要标准是“方便”。就拿抽取页面所有链接这一基本任务来说，几种代码分别如下：</p>

<p>XPath:</p>

<figure class='code'><figcaption><span>XPath提取链接 </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'>     <span class="n">tagNode</span><span class="o">.</span><span class="na">evaluateXPath</span><span class="o">(</span><span class="s">&quot;//a/@href&quot;</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>CSS Selector:</p>

<figure class='code'><figcaption><span>CSS Selector提取链接 </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'>     <span class="c1">//使用类似js的实现</span>
</span><span class='line'>      <span class="n">$</span><span class="o">(</span><span class="s">&quot;a[href]&quot;</span><span class="o">).</span><span class="na">attr</span><span class="o">(</span><span class="s">&quot;href&quot;</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>HtmlParser：</p>

<figure class='code'><figcaption><span>HtmlParser提取链接 </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'>        <span class="n">Parser</span> <span class="n">p</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Parser</span><span class="o">(</span><span class="n">value</span><span class="o">);</span>
</span><span class='line'>        <span class="n">NodeFilter</span> <span class="n">aFilter</span> <span class="o">=</span> <span class="k">new</span> <span class="n">TagNameFilter</span><span class="o">(</span><span class="s">&quot;a&quot;</span><span class="o">);</span>
</span><span class='line'>        <span class="n">NodeList</span> <span class="n">nodes</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="na">extractAllNodesThatMatch</span><span class="o">(</span><span class="n">aFilter</span><span class="o">);</span>
</span><span class='line'>        <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">nodes</span><span class="o">.</span><span class="na">size</span><span class="o">();</span> <span class="n">i</span><span class="o">++)</span> <span class="o">{</span>
</span><span class='line'>            <span class="n">Node</span> <span class="n">eachNode</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="na">elementAt</span><span class="o">(</span><span class="n">i</span><span class="o">);</span>
</span><span class='line'>            <span class="k">if</span> <span class="o">(</span><span class="n">eachNode</span> <span class="k">instanceof</span> <span class="n">LinkTag</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>                <span class="n">LinkTag</span> <span class="n">linkTag</span> <span class="o">=</span> <span class="o">(</span><span class="n">LinkTag</span><span class="o">)</span> <span class="n">eachNode</span><span class="o">;</span>
</span><span class='line'>                <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">linkTag</span><span class="o">.</span><span class="na">extractLink</span><span class="o">());</span>
</span><span class='line'>            <span class="o">}</span>
</span><span class='line'>        <span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>XPath是最简单的，可以精确选取到href属性值；而CSS Selector则次之，可以选取到HTML标签，属性值需要调用函数去获取；而HtmlParser和SAX则需要手动写程序去处理标签了，比较麻烦。</p>

<h4>webmagic的Selector</h4>

<p><strong>Selector</strong>是webmagic为了简化页面抽取开发的独立模块，是整个项目中我最得意的部分。这里整合了CSS Selector、XPath和正则表达式，并可以进行链式的抽取，很容易就实现强大的功能。即使你使用自己开发的爬虫工具，webmagic的Selector仍然值得一试。</p>

<p>例如，我已经下载了一个页面，现在要抽取某个区域的所有包含&#8221;blog&#8221;的链接，我可以这样写：</p>

<figure class='code'><figcaption><span>webmagic的链式抽取 </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'>     <span class="c1">//content是用别的爬虫工具抽取到的正文</span>
</span><span class='line'>      <span class="n">String</span> <span class="n">content</span> <span class="o">=</span> <span class="s">&quot;blabla&quot;</span><span class="o">;</span>
</span><span class='line'>      <span class="n">List</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">links</span> <span class="o">=</span> <span class="n">Html</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">content</span><span class="o">)</span>
</span><span class='line'>      <span class="o">.</span><span class="n">$</span><span class="o">(</span><span class="s">&quot;div.title&quot;</span><span class="o">)</span>  <span class="c1">//css 选择，Java里虽然很少有$符号出现，不过貌似$作为方法名是合法的</span>
</span><span class='line'>      <span class="o">.</span><span class="na">xpath</span><span class="o">(</span><span class="s">&quot;//@href&quot;</span><span class="o">)</span>  <span class="c1">//提取链接</span>
</span><span class='line'>      <span class="o">.</span><span class="na">regex</span><span class="o">(</span><span class="s">&quot;.*blog.*&quot;</span><span class="o">)</span> <span class="c1">//正则匹配过滤</span>
</span><span class='line'>      <span class="o">.</span><span class="na">toStrings</span><span class="o">();</span> <span class="c1">//转换为string</span>
</span></code></pre></td></tr></table></div></figure>


<p>另外，webmagic的抓取链接需要显示的调用<code>Page.addTargetRequests()</code>去添加，这也是为了灵活性考虑的(很多时候，下一步的URL不是单纯的页面href链接，可能会根据页面模块进行抽取，甚至可能是自己拼凑出来的)。</p>

<p>补充一个有意思的话题，就是对于页面正文的自动抽取。相信用过Evernote Clearly都会对其自动抽取正文的技术印象深刻。这个技术又叫<strong>Readability</strong>，webmagic对readability有一个粗略的实现<strong>SmartContentSelector</strong>，用的是P标签密度计算的方法，在测试oschina博客时有不错的效果。</p>

<h3>Scheduler-URL管理</h3>

<p>URL管理的问题可大可小。对于小规模的抓取，URL管理是很简单的。我们只需要将待抓取URL和未抓取URL分开保存，并进行去重即可。使用JDK内置的集合类型Set、List或者Queue都可以满足需要。如果我们要进行多线程抓取，则可以选择线程安全的容器，例如LinkedBlockingQueue以及ConcurrentHashMap。</p>

<p>因为小规模的URL管理非常简单，很多框架都并不将其抽象为一个模块，而是直接融入到代码中。但是实际上，抽象出Scheduler模块，会使得框架的解耦程度上升一个档次，并非常容易进行横向扩展，这也是我从scrapy中学到的。</p>

<p>在webmagic的设计中，除了Scheduler模块，其他的处理-从下载、解析到持久化，每个任务都是互相独立的，因此可以通过多个Spider共用一个Scheduler来进行扩展。排除去重的因素，URL管理天生就是一个队列，我们可以很方便的用分布式的队列工具去扩展它，也可以基于mysql、redis或者mongodb这样的存储工具来构造一个队列，这样构建一个多线程乃至分布式的爬虫就轻而易举了。</p>

<p>URL去重也是一个比较复杂的问题。如果数据量较少，则使用hash的方式就能很好解决。数据量较大的情况下，可以使用Bloom Filter或者更复杂的方式。</p>

<p>webmagic目前有两个Scheduler的实现，<strong>QueueScheduler</strong>是一个简单的内存队列，速度较快，并且是线程安全的，<strong>FileCacheQueueScheduler</strong>则是一个文件队列，它可以用于耗时较长的下载任务，在任务中途停止后，下次执行仍然从中止的URL开始继续爬取。</p>

<h3>Pipeline-离线处理和持久化</h3>

<p>Pipeline其实也是容易被忽略的一部分。大家都知道持久化的重要性，但是很多框架都选择直接在页面抽取的时候将持久化一起完成，例如crawer4j。但是Pipeline真正的好处是，将页面的在线分析和离线处理拆分开来，可以在一些线程里进行下载，另一些线程里进行处理和持久化。</p>

<p>你可以扩展Pipeline来实现抽取结果的持久化，将其保存到你想要保存的地方-本地文件、数据库、mongodb等等。Pipeline的处理目前还是在线的，但是修改为离线的也并不困难。</p>

<p>webmagic目前只支持控制台输出和文件持久化，但是持久化到数据库也是很容易的。</p>

<h2>结语</h2>

<p>webmagic确实是一个山寨的框架，本身也没有太多创新的东西，但是确实对Java爬虫的实现有了一些简化。在强大便利的功能和较高的灵活性中间，webmagic选择了后者，目标就是要打造一个熟练的Java开发者也用的比较顺手的工具，并且可以集成到自己的业务系统中，这一点我自己开发了不少这样的业务，对其灵活性还是比较有信心的。webmagic目前的代码实现还比较简单(不到2000行)，如果有兴趣的阅读代码可能也会有一些收获，也非常欢迎建议和指正。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[monkeysocks架构规划]]></title>
    <link href="http://code4craft.github.com/blog/2013/07/07/monkeysocks-arch/"/>
    <updated>2013-07-07T21:35:00+08:00</updated>
    <id>http://code4craft.github.com/blog/2013/07/07/monkeysocks-arch</id>
    <content type="html"><![CDATA[<blockquote><p>monkeysocks的目标是为开发以及测试提供一个稳定的环境。它使用socks代理，将录制网络流量并本地保存，并在测试时将其重放。</p></blockquote>

<h2>jsocks的改造</h2>

<p>首先对公司一个项目进行了代理，测试结果：从开始启动到完成，只有4.7M的网络流量，本地空间开销不是问题。</p>

<p>今天把jsocks修改了下，将build工具换成了maven，并独立成了项目<a href="https://github.com/code4craft/monkeysocks/jsocks">https://github.com/code4craft/jsocks</a>。后来算是把record和replay功能做完了，开始研究各种协议replay的可能性。</p>

<!--more-->


<p>replay时候，如何知道哪个请求对应响应包是个大问题。开始的方式是把request报文的md5作为key，response作为value。</p>

<h2>TCP协议分析</h2>

<p>后来使用wiredshark结合程序日志来进行分析。</p>

<p>TCP协议栈大概是这样子：
<img src="http://www.skullbox.net/diagrams/tcppacket.gif?dur=673" alt="image" /></p>

<p>下面是wiredshark抓包的截图，从ea开始才是应用层协议的内容。</p>

<p><img src="http://code4craft.github.io/images/posts/tcp-wiredshark.png" alt="image" /></p>

<h2>应用层协议分析</h2>

<p>实现replay后，拿HTTP协议做了测试，自己用程序写了个URLConnection，倒是能够实现replay，但是换到浏览器里就很难了，因为cookie总是会有些不一样(现在基本上所有站点都会写cookie吧)。如果不对应用层协议本身进行分析，那么进行包的伪造就很难了。</p>

<p>https协议对于重放攻击做了处理，每次的请求包都不一样，也无法replay成功，暂时略过。</p>

<p>后来对于测试中得重点协议&mdash;mysql的协议，进行了研究。</p>

<p>这是一个有状态的协议，状态转移图如下：</p>

<p><img src="http://dev.mysql.com/doc/internals/en/images/graphviz-db6c3eaf9f35f362259756b257b670e75174c29b.png" alt="image" /></p>

<p>详细介绍<a href="http://dev.mysql.com/doc/internals/en/client-server-protocol.html">http://dev.mysql.com/doc/internals/en/client-server-protocol.html</a>，有点hold不住的感觉啊！</p>

<p>看了Authentication部分，会由server端发送一个随机数，来避免重放攻击。这个东西启发了我，因为主动权一般都是在server端，而我们要对client进行欺骗，难度就小了很多。</p>

<h2>架构设计</h2>

<p>后来决定把架构解耦了，fake server单独作为一个模块，可以单独启动成TCP server，也可以加入到jsocks里。最后架构是这样子：</p>

<p><img src="http://code4craft.github.io/images/posts/monkeysocks-arch.png" alt="image" /></p>

<p>fake servers的实现必定是个大坑，不过能把常用协议都了解一遍，本身也很有意思不是么？</p>

<h2>开发计划：</h2>

<ul>
<li><p>实现fake servers的TCP框架。</p></li>
<li><p>研究并实现常用协议的fake server。</p></li>
<li><p>确定持久化以及报文对应的策略。</p></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[monkeysocks开发日志]]></title>
    <link href="http://code4craft.github.com/blog/2013/07/06/monkeysocks/"/>
    <updated>2013-07-06T16:09:00+08:00</updated>
    <id>http://code4craft.github.com/blog/2013/07/06/monkeysocks</id>
    <content type="html"><![CDATA[<blockquote><p>monkeysocks的目标是为开发以及测试提供一个稳定的环境。</p></blockquote>

<h4>2013-7-5 动机</h4>

<p>前几天听说公司的测试团队在鼓捣数据固化的东西，说白了就是在测试启动时构建一个临时性的数据库，操作完之后再销毁，这样的好处是不造成测试副作用，同时屏蔽环境的差异。</p>

<!--more-->


<p>但是目前公司内部SOA用的太多了，仅仅靠数据库固化明显不现实，公司的架构团队做了一个将所有remote service放到本地启动的东西，但是这样子启动开销有点难以接受。有没有更可行的方案？</p>

<p>之前也有人做过一个单测的东西，可以将所有RPC调用的结果序列化成文本文件，下次调用时再序列化出来，这样其实就屏蔽了远程调用。但是Java语言层面的机制导致要把千奇八怪的对象序列化下来，本来就是不可完成的任务(有些对象本身就不是POJO，还有在getter、setter写逻辑的)。</p>

<p>于是我有一个大胆的设想：其实Java的外部依赖无非是网络IO，就是TCP/UDP包嘛，那我能不能做一个工具，录制一个稳定环境的网络流量，然后固化下来，最终在调用时进行重放，岂不是一劳永逸？</p>

<p>但是TCP/UDP毕竟是系统底层的东西，而且我想对每个Java进程单独做重放，所以只能从Java内部机制入手了。</p>

<p>有两个方法：</p>

<p>用cglib改写所有网络IO相关的接口，改用固化调用。</p>

<p>设置Java全局socks代理，并启动socks server，在socks server里做代理。</p>

<p>显然第二种方法更简单，有四两拨千斤的感觉！</p>

<p>找到一个Java socks server，jsocks，最初版本比较老，google code上有一个改进版，用的是ant，因为以后要集成肯定要用maven，于是就做了点maven化的处理，考虑以后单独做成一个项目，现在先改了测试下可行性吧。<a href="https://github.com/code4craft/monkeysocks/jsocks">https://github.com/code4craft/jsocks</a></p>

<p>Java里面设置全局socksProxy的方法见<a href="http://docs.oracle.com/javase/6/docs/technotes/guides/net/proxies.html">http://docs.oracle.com/javase/6/docs/technotes/guides/net/proxies.html</a>。</p>

<p>鼓捣一下，成功启动起来，明天先对公司的项目进行试用。</p>

<h4>2013-7-6</h4>

<p>今天开始了对socks的摸索。</p>

<p>首先对公司一个项目进行了代理，测试结果：从开始启动到完成，只有4.7M的网络流量，本地空间开销不是问题。</p>

<p>想到咱这个不就是个TCP重放攻击么？了解了一下一些协议防重放攻击的机制，发现大多是在server端做，那么其实client端的请求并无不同，希望是这样！</p>

<p>研究了一下http协议，response竟然有date项，希望不会作为判断依据，要不然还要做http解析，那就纠结了！怎么觉得自己老是在研究怎么实现一个gfw呢？</p>

<p>在测试中，遇到了问题：</p>

<p>很多协议里都自带了版本号，比如<a href="http://www.hoterran.info/mysql-protocol-soucecode-2">mysql</a>、zookeeper，这样就给识别请求和伪造响应带来了难度。幸好公司内部用的工具不是太多，理论上还是在可控状态。</p>

<p>最终决定结构大概是这样子：</p>

<p><img src="http://code4craft.github.io/images/posts/mocksocks-flow-in.png" alt="image" /></p>

<p><img src="http://code4craft.github.io/images/posts/mocksocks-flow-out.png" alt="image" /></p>

<p>晚上尝试了一下，jsocks的流程写的过于凌乱，最终缓存结构也没定好，不说了，碎觉！</p>

<h4>2013-7-7</h4>

<p>鼓捣了下架构的事情，文章单独整理了下，链接：<a href="http://code4craft.github.io/blog/2013/07/07/monkeysocks-arch/">http://code4craft.github.io/blog/2013/07/06/monkeysocks-arch/</a></p>

<h4>2013-7-8</h4>

<p>今天跟水哥讨论起两个问题，假设拿到一个报文byte[]，存在两个难点，一个是对于可变部分的判断和伪造，另一个是对于包结构的近似匹配。</p>

<p>可变部分的的判断，水哥说可以用录两次，去掉不同的部分，就变成一个不变的基和一个过滤器，然后对于以后的包，就用过滤器过滤后找到这个基。</p>

<p>包结构的近似匹配，水哥提议对包的所有字节进行求和，过滤掉位置信息，似乎也是可行的方向？</p>

<p>用Java实现一个流管道：</p>

<p><a href="http://ostermiller.org/convert_java_outputstream_inputstream.html">http://ostermiller.org/convert_java_outputstream_inputstream.html</a></p>

<h4>2013-7-9</h4>

<p>使用byte和条件变量实现了一个Java流的管道，线程安全的，debug了好久终于成功，当年操作系统的知识还是没还给老师！<a href="https://github.com/code4craft/monkeysocks/blob/master/monkeysocks-server/src/main/java/com/dianping/monkeysocks/socket/StreamBuffer.java">https://github.com/code4craft/monkeysocks/blob/master/monkeysocks-server/src/main/java/com/dianping/monkeysocks/socket/StreamBuffer.java</a></p>

<p>这个东东使得伪造一个Socket成为了可能，下面就是使用Socket API实现fake servers的逻辑了。</p>

<h4>2013-7-11</h4>

<p>昨天太累了，项目又比较忙，先休息一天。</p>

<p>今天早上考虑用自己写的TCP server框架把jsocks的连接部分重写一遍(那堆代码全部在一个类中，实在是太复杂了)，想到
今天早上想了下InputStream这些玩意，觉得这样总会占用一个线程去把Stream转来转去的，弄成onReceive()这样的异步调用的话，就很容易做到链式调用了。</p>

<p>这东西太费脑子了，先休息一天半天再说。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[玩转github之--神啊满足我的虚荣心吧]]></title>
    <link href="http://code4craft.github.com/blog/2013/07/03/show-in-github/"/>
    <updated>2013-07-03T07:47:00+08:00</updated>
    <id>http://code4craft.github.com/blog/2013/07/03/show-in-github</id>
    <content type="html"><![CDATA[<h3>github版简历</h3>

<p><a href="http://resume.github.io/">http://resume.github.io/</a>上有这个东东，但是样式太难看了。看到一个挺不错的模板<a href="https://github.com/hit9/GhResume">https://github.com/hit9/GhResume</a>，就给用上了。我的简历：
<a href="http://code4craft.github.io/GhResume/">http://code4craft.github.io/GhResume/</a></p>

<h3>关注star</h3>

<p>最近做的项目在github每天会有几个star，出于虚荣心嘛，经常忍不住就会去看看，有人star了没？有人fork了没？</p>

<p>每天看太麻烦了，干脆做成一个chrome插件，带桌面通知，有新star提醒，岂不开心？</p>

<p>于是有了<a href="https://github.com/code4craft/exciting"><strong>exciting</strong></a>！ 哥也会做chrome插件了！液！</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[一个shell下的todolist]]></title>
    <link href="http://code4craft.github.com/blog/2013/06/28/todolist/"/>
    <updated>2013-06-28T10:17:00+08:00</updated>
    <id>http://code4craft.github.com/blog/2013/06/28/todolist</id>
    <content type="html"><![CDATA[<p>使用和文件保存都挺简单，试试看吧！</p>

<p><a href="http://todotxt.com/">http://todotxt.com/</a>貌似还能同步到手机端？</p>

<p>下载之后，</p>

<pre><code>ln -s xxx/todo.sh /usr/local/bin/todo
</code></pre>

<p>貌似这样会把东西存到/usr/local/bin/todo.txt里？不管了！</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[写了个快捷保存文本的shell工具]]></title>
    <link href="http://code4craft.github.com/blog/2013/06/27/yong-pythonxie-liao-ge-xiao-gong-ju/"/>
    <updated>2013-06-27T22:14:00+08:00</updated>
    <id>http://code4craft.github.com/blog/2013/06/27/yong-pythonxie-liao-ge-xiao-gong-ju</id>
    <content type="html"><![CDATA[<p>作为一个Java程序员，对脚本语言程序员自己随时写些小工具，已经羡慕很久了，于是最终开始了脚本语言的学习。</p>

<!-- more -->


<p>第一个工具是个助记程序。像工作中我们总会管理一些文本，比如内网服务器地址、git仓库地址什么的，之前一直都是要登录一个平台去拷贝下来，然后粘贴到shell里，特别麻烦。想写了个工具，为一个文本写一个助记符，然后保存到文件里，每次可以调用程序把文件读出来，再根据助记符查找到对应文本。用法可以这样：</p>

<pre><code>add alias text
get alias
</code></pre>

<p>例如：</p>

<pre><code>add getter https://github.com/code4craft/getter 
</code></pre>

<p>也可以用&#8220;符号穿插到程序里：</p>

<pre><code>git clone `get getter`
</code></pre>

<p>刚开始用python写了一遍，把文件保存到~/.getrc，并每次读出来并更新。</p>

<p>后来想了想，这个方法没有自动补全，太麻烦！有没有好办法？最终想到，干脆把name作为可执行文件名，value作为程序的输出，每个name对应一个输出，再以特定前缀开始，这样子也有自动提示了，岂不是更好？于是就有了shell版本：</p>

<pre><code>add.sh

 #!/bin/sh
FILE_PATH=/usr/local/getter
PREFIX=-
[ -d "$FILE_PATH" ] || mkdir -p $FILE_PATH
if [ -z "$1" ]
then
    echo "Usage: $0 alias [text]"
else
    FILE_NAME=$FILE_PATH/$PREFIX$1
    if [ -z "$2" ]
    then
        rm -f $FILE_NAME
    else
        echo "#!/bin/sh" &gt; $FILE_NAME
        echo "echo \"$2\"" &gt;&gt; $FILE_NAME
        chmod +x $FILE_NAME
    fi
fi
</code></pre>

<p>记得在/etc/bashrc中加一行</p>

<pre><code>export PATH=$PATH:/usr/local/getter
</code></pre>

<p>后来一想，那么如果我要保存一个可执行的shell命令，执行时是不是要<code>-xx</code>?干脆把命令直接写到脚本里，也别echo了！</p>

<pre><code>edd.sh

 #!/bin/sh
FILE_PATH=/usr/local/getter
PREFIX=-
[ -d "$FILE_PATH" ] || mkdir -p $FILE_PATH
if [ -z "$1" ]
then
    echo "Usage: $0 alias [command]"
else
    FILE_NAME=$FILE_PATH/$PREFIX$1
    if [ -z "$2" ]
    then
        rm -f $FILE_NAME
    else
        echo "#!/bin/sh" &gt; $FILE_NAME
        echo "$2 \$1 \$2 \$3" &gt;&gt; $FILE_NAME
        chmod +x $FILE_NAME
    fi
fi
</code></pre>

<p>比如之后我要保存一条命令&#8221;curl <a href="http://code4craft.github.io/blackhole/install.sh">http://code4craft.github.io/blackhole/install.sh</a> | sh&#8221;，可以这么用：</p>

<pre><code>#保存命令
edd install "curl http://code4craft.github.io/blackhole/install.sh | sh"
#执行命令
-install
</code></pre>

<p>代码已经放到了github:</p>

<p><a href="https://github.com/code4craft/getter">https://github.com/code4craft/getter</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[BlackHole开发日记-一次压力测试及JVM调优的经过]]></title>
    <link href="http://code4craft.github.com/blog/2013/06/23/%5B%3F%5D-ci-jvmdiao-you-de-jing-guo/"/>
    <updated>2013-06-23T06:44:00+08:00</updated>
    <id>http://code4craft.github.com/blog/2013/06/23/[?]-ci-jvmdiao-you-de-jing-guo</id>
    <content type="html"><![CDATA[<p>BlackHole开发很久了，目前稳定性、性能都还可以了，但是作为一个Java程序，内存开销一直是硬伤，动不动100M内存下去了，对于单机用户实在是不太友好。</p>

<p>怎么办？优化先从分析开始！</p>

<h3>获取内存信息</h3>

<p>获取内存信息一般使用jmap。</p>

<pre><code>jmap -histo pid
</code></pre>

<p>这种方式获取到得比较简略，我们可以先把内存dump下来，再进行离线分析。jhat是一个离线内存分析工具，会开启一个web服务以供展示。</p>

<pre><code>jmap -dump:file=dumpfile pid
jhat -J-Xmx512m dumpfile
</code></pre>

<!-- more -->


<p>访问<a href="http://127.0.0.1:7000%E5%8D%B3%E5%8F%AF%E3%80%82%E9%BB%98%E8%AE%A4%E6%98%AFClass%E5%88%97%E8%A1%A8%EF%BC%8C%E7%BF%BB%E5%88%B0%E9%A1%B5%E9%9D%A2%E5%BA%95%E9%83%A8%E5%8F%AF%E4%BB%A5%E6%9F%A5%E7%9C%8B%E5%85%B6%E4%BB%96%E5%8A%9F%E8%83%BD%E3%80%82">http://127.0.0.1:7000%E5%8D%B3%E5%8F%AF%E3%80%82%E9%BB%98%E8%AE%A4%E6%98%AFClass%E5%88%97%E8%A1%A8%EF%BC%8C%E7%BF%BB%E5%88%B0%E9%A1%B5%E9%9D%A2%E5%BA%95%E9%83%A8%E5%8F%AF%E4%BB%A5%E6%9F%A5%E7%9C%8B%E5%85%B6%E4%BB%96%E5%8A%9F%E8%83%BD%E3%80%82</a></p>

<p>参考资料：</p>

<p><a href="http://www.lhelper.org/newblog/?tag=jhat">http://www.lhelper.org/newblog/?tag=jhat</a>
<a href="http://blog.csdn.net/gtuu0123/article/details/6039474">http://blog.csdn.net/gtuu0123/article/details/6039474</a></p>

<h3>详细分析</h3>

<p>以下分析仅针对JDK 7 HotSpot虚拟机。jmap -histo的结果：</p>

<pre><code>num     #instances         #bytes  class name
----------------------------------------------
 1:         28490        4057072  &lt;constMethodKlass&gt;
 2:         28490        3882464  &lt;methodKlass&gt;
 3:          2630        2820064  &lt;constantPoolKlass&gt;
 4:         46350        2412600  &lt;symbolKlass&gt;
 5:         32778        2372824  [C
 6:          2630        1990744  &lt;instanceKlassKlass&gt;
 7:          3418        1955208  [I
 8:         15491        1911568  [B
 9:          2347        1845400  &lt;constantPoolCacheKlass&gt;
10:         19246         615872  java.lang.String
11:           256         561152  [Lnet.sf.ehcache.store.chm.SelectableConcurrentHashMap$HashEntry;
12:          2930         304720  java.lang.Class
13:          3740         247280  [S
14:          4321         221520  [[I
</code></pre>

<p>其中[开头表示数组，[C [I [B 分别是char[] int[] byte[]。</p>

<p>constMethodKlass、都实现自sun.jvm.hotspot.oops.Klass，用于在永久代里保存类的信息。</p>

<p>换到JDK6之后，发现永久代的消耗下去了。</p>

<pre><code>num     #instances         #bytes  class name
----------------------------------------------
 1:         10823        3072312  [B
 2:         16605        2318720  &lt;constMethodKlass&gt;
 3:         18687        1388088  [C
 4:         16605        1328608  &lt;methodKlass&gt;
 5:         27595        1296832  &lt;symbolKlass&gt;
 6:          1699         940392  &lt;constantPoolKlass&gt;
 7:          2520         883408  [I
 8:          1699         724944  &lt;instanceKlassKlass&gt;
 9:          1472         565136  &lt;constantPoolCacheKlass&gt;
10:           256         561152  [Lnet.sf.ehcache.store.chm.SelectableConcurrentHashMap$HashEntry;
11:         12148         291552  java.lang.String
12:          4505         288320  net.sf.ehcache.Element
13:          7290         233280  java.lang.ThreadLocal$ThreadLocalMap$Entry
14:          1946         186816  java.lang.Class
15:          4509         180360  net.sf.ehcache.store.chm.SelectableConcurrentHashMap$HashEntry
</code></pre>

<p>查看一下总的内存开销(参考资料:
<a href="http://yytian.blog.51cto.com/535845/574527">http://yytian.blog.51cto.com/535845/574527</a>)</p>

<pre><code>ps -e -o 'pid,comm,args,pcpu,rsz' | grep java |  sort -nrk5
1239 java            java -jar -Djava.io.tmpdir=  0.1 52816
</code></pre>

<p>或者：</p>

<pre><code>top -pid pid
</code></pre>

<p>查看到只有52m，看来JDK7占用内存果然增加了！</p>

<h3>压力测试</h3>

<p>使用140,000个随机域名做压力测试。发现之前使用的JDK7 Developer Preview u04，在短时间产生大量对象的时候，GC会失去作用，内存迅速飙升到200M，后来更新到1.7.0u25，稳定到了130m，qps大概在49000~50000之间。</p>

<p>尝试使用ConcurrentHashMap代替EhCache，qps提高到50000~51000之间，变化不明显，EhCache还是相当优秀的。</p>

<p>为了提高吞吐量，查看GC情况:</p>

<pre><code>sudo jstat -gcutil 2960
S0     S1     E      O      P     YGC     YGCT    FGC    FGCT     GCT   
0.00   0.75  30.35  12.06  72.92     25    0.063     0    0.000    0.063
</code></pre>

<p>140,000个请求产生了25次YGC。</p>

<p>参考了关于JVM的调优文章<a href="http://blog.csdn.net/kthq/article/details/8618052">http://blog.csdn.net/kthq/article/details/8618052</a></p>

<p>重新设置新生代为200m，并开启并行收集：</p>

<pre><code>JVM_OPTION="-XX:+UseParallelGC -XX:NewSize=200m"
</code></pre>

<p>140,000个请求只产生了3次YGC，但是qps变化并不明显。看来新生代设置大之后，虽然YGC少了，但是一次回收的时间多了，最终其实没啥影响啊，那还是弄小一点好了。</p>

<p>看来折腾JVM效果不明显，除了内存开销之外，其他没有明显变化。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[换电脑了]]></title>
    <link href="http://code4craft.github.com/blog/2013/06/22/huan-dian-nao-liao/"/>
    <updated>2013-06-22T08:57:00+08:00</updated>
    <id>http://code4craft.github.com/blog/2013/06/22/huan-dian-nao-liao</id>
    <content type="html"><![CDATA[<p>公司政策，每个人给6500软妹币报销，可以买电脑。因为刚好WWDC开完，老AIR降价，本着好用和省钱的标准，就买了老AIR一台，7388包发票。</p>

<p>换到AIR最不习惯的是屏幕，PRO的屏幕是1280*800，AIR的屏幕是1440x900，所以字总是特小，原来12pt的字体非要14pt才能显示出来，MAC还没法设置默认字体，只能装了个Tinker Tool。设置之后，各种丑和切边…没办法，办公用，眼睛不累是原则！</p>

<p>换电脑之后，得把老的东西弄过来。这次RVM倒是一次成功了，换了gem的source为淘宝的，更新还挺快的。octpress又重新装了一次，好像ruby的包好多都是安装到一个目录下可用的？最后只能把原来的octpress连同博客一起拷贝过来了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用webmagic抓取页面并保存为wordpress文件]]></title>
    <link href="http://code4craft.github.com/blog/2013/06/10/shi-yong-webmagiczhua-qu-ye-mian-bing-bao-cun-wei-wordpresswen-jian/"/>
    <updated>2013-06-10T18:05:00+08:00</updated>
    <id>http://code4craft.github.com/blog/2013/06/10/shi-yong-webmagiczhua-qu-ye-mian-bing-bao-cun-wei-wordpresswen-jian</id>
    <content type="html"><![CDATA[<p>之前做过一年的爬虫，当年功力不够，写的代码都是一点一点往上加。后来看了下据说是最优秀的爬虫<a href="http://www.oschina.net/p/scrapy"><code>scrapy</code></a>的结构，山寨了一个Java版的爬虫框架。</p>

<p>这个框架也分为Spider、Schedular、Downloader、Pipeline几个模块。此外有一个Selector，整合了常用的抽取技术(正则、xpath)，支持链式调用以及单复数切换，因为受够了各种抽取的正则，在抽取上多下了一点功夫。</p>

<!-- more -->


<p>废话不多，上代码。在webmagic里直接实现PageProcessor接口，即可实现一个爬虫。例如对我的点点博客<a href="http://progressdaily.diandian.com/">http://progressdaily.diandian.com/</a>进行抓取：</p>

<pre><code>    public class DiandianBlogProcessor implements PageProcessor {

        private Site site;

        @Override
        public void process(Page page) {
            //a()表示提取链接，as()表示提取所有链接
            //getHtml()返回Html对象，支持链式调用
            //r()表示用正则表达式提取一条内容，rs()表示提取多条内容
            //toString()表示取单条结果，toStrings()表示取多条
            List&lt;String&gt; requests = page.getHtml().as().rs("(.*/post/.*)").toStrings();
            //使用page.addTargetRequests()方法将待抓取的链接加入队列
            page.addTargetRequests(requests);
            //page.putField(key,value)将抽取的内容加入结果Map
            //x()和xs()使用xpath进行抽取
            page.putField("title", page.getHtml().x("//title").r("(.*?)\\|"));
            //sc()使用readability技术直接抽取正文，对于规整的文本有比较好的抽取正确率
            page.putField("content", page.getHtml().sc());
            page.putField("date", page.getUrl().r("post/(\\d+-\\d+-\\d+)/"));
            page.putField("id", page.getUrl().r("post/\\d+-\\d+-\\d+/(\\d+)"));
        }

        @Override
        public Site getSite() {
            //site定义抽取配置，以及开始url等
            if (site == null) {
                site = Site.me().setDomain("progressdaily.diandian.com").setStartUrl("http://progressdaily.diandian.com/").
                        setUserAgent("Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_2) AppleWebKit/537.31 (KHTML, like Gecko) Chrome/26.0.1410.65 Safari/537.31");
            }
            return site;
        }
    }
</code></pre>

<p>然后实现抓取代码：</p>

<pre><code>    public class DiandianProcessorTest {

        @Test
        public void test() throws IOException {
            DiandianBlogProcessor diandianBlogProcessor = new DiandianBlogProcessor();
            //pipeline是抓取结束后的处理
            //ftl文件放到classpath:ftl/文件夹下
            //默认放到/data/temp/webmagic/ftl/[domain]目录下
            FreemarkerPipeline pipeline = new FreemarkerPipeline("wordpress.ftl");
            //Spider.me()是简化写法，其实就是new一个啦
            //Spider.pipeline()设定一个pipeline，支持链式调用
            //ConsolePipeline输出结果到控制台
            //FileCacheQueueSchedular保存url，支持断点续传，临时文件输出到/data/temp/webmagic/cache目录
            //Spider.run()执行
            Spider.me().pipeline(new ConsolePipeline()).pipeline(pipeline).schedular(new FileCacheQueueSchedular(diaoyuwengProcessor.getSite(), "/data/temp/webmagic/cache/")).
                    processor(diaoyuwengProcessor).run();
        }
    }
</code></pre>

<p>跑一遍之后，将所有输出的文件，合并到一起，并加上wp的<a href="https://github.com/code4craft/webmagic/tree/master/webmagic-samples/src/main/resources">头尾</a>，就是wordpress-backup.xml了！</p>

<p>代码已开源<a href="https://github.com/code4craft/webmagic">https://github.com/code4craft/webmagic</a><strike>有什么邪恶用途你懂的…</strike></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[2013年半年总结及计划]]></title>
    <link href="http://code4craft.github.com/blog/2013/06/07/2013nian-ban-nian-zong-jie-ji-ji-hua/"/>
    <updated>2013-06-07T07:08:00+08:00</updated>
    <id>http://code4craft.github.com/blog/2013/06/07/2013nian-ban-nian-zong-jie-ji-ji-hua</id>
    <content type="html"><![CDATA[<p>2013年前半年搞Scrum，工作忙了不少，但是却是瞎忙的多。</p>

<p>持续维护<code>BlackHole</code>半年时间，github上有了 <strong>24</strong> 个star，半年来最大的成果。</p>

<!-- more -->


<p>看了 <strong> 3 </strong> 本书，比较少：</p>

<p>《git权威指南》、《硝烟中的Scrum和XP》、《七周七语言》</p>

<p>又写了两个项目：</p>

<p><code>webmagic</code>(爬虫框架)和<code>hostd</code>(BlackHole衍生管理工具)</p>

<p>阅读代码：</p>

<p>读了公司的JMS框架swallow、RPC框架Pigeon。</p>

<p>尝试阅读Jetty源码，未果。</p>

<p>学些了一门新语言：</p>

<p><code>Javascript</code></p>

<p>写了20篇技术博客，有一篇上了oschina首页。</p>

<p>在微博上做了个<code>每天学点新工具</code>系列，发了 <strong> 7 </strong> 条微博。</p>

<p>量上有所下降，特别是读书一项。</p>

<p>玩新东西多了，钻研少了。</p>

<p>下半年的计划是找一个Web服务器进行深入研究。</p>

<p>Jetty、Tomcat、Netty、nginx选一个吧。</p>

<p>Jetty最简单，看到一半了，学习的应该是架构、设计的东西。</p>

<p>Tomcat比较复杂，据说代码可读性也不太好，但是毕竟是目前使用的容器，可以试试。</p>

<p>Netty，学好这个，做个中间件是信手拈来的事，这方面需求挺多的。难处是用的比较少，难以把握其原理。</p>

<p>nginx源码挑战最大，但是收获应该最多，进入c世界？BlackHole自认为也是一个高性能服务器了，跟nginx比比，这样会对高性能Web服务有个全面的认识。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[IntelliJ使用心得]]></title>
    <link href="http://code4craft.github.com/blog/2013/04/17/intellijshi-yong-xin-de/"/>
    <updated>2013-04-17T21:18:00+08:00</updated>
    <id>http://code4craft.github.com/blog/2013/04/17/intellijshi-yong-xin-de</id>
    <content type="html"><![CDATA[<p>最近尝鲜试用了一下IntelliJ，使用下来还是比较爽的，最后我这个很少花钱买软件的人，也在oschina上买了个人版。IDE毕竟是码农干活的家伙，想想也值了。使用的时候有一些心得，记录下来。</p>

<!-- more -->


<h3>调整界面为酷酷的黑色</h3>

<p>Preferences=>Appearance=>theme=>Darcula</p>

<h3>检出项目:</h3>

<p>VCS=>Checkout From Version Control，maven项目会被自动识别出来。</p>

<h3>设置快捷键：</h3>

<p>Preferences=>keymaps，有很多套方案，当然即使选择Eclipse也还是有很多和Eclipse不同的地方。</p>

<h3>自动补全：</h3>

<p>Mac下默认是clt+space，可以使用keymaps=>Main menu=>Code=>Competion设置。</p>

<h3>去除自动补全的大小写敏感：</h3>

<p>不知道多少童鞋和我一样被Eclipse惯坏了，使用自动补全完全不注意大小写的，IntelliJ默认区分大小写，很是让人难过。不过在Editor=>Code Completion里把Case sensitive completion设置为None就可以了。</p>

<h3>自动展开目录</h3>

<p>Eclipse有个打开文件就自动展开目录的功能，在IntelliJ里从Project左边栏的齿轮上选择Autoscroll to Source和Autoscroll from Source都勾选上即可。</p>

<h3>使用Tomcat运行web项目：</h3>

<p>需安装插件：Tomcat and TomEE intergration</p>

<p>选择Run=>Edit Configurations，点+，选tomcat server，Deloyment选择对应artifact。详细文章：<a href="http://my.oschina.net/tsl0922/blog/94621">http://my.oschina.net/tsl0922/blog/94621</a></p>

<h3>项目间文件复制</h3>

<p>IntelliJ里的工作空间是Project，不同Project之间是没有什么关系的。在一个Project里copy&amp;paste，会弹出对话框，让你选择<strong>目标文件夹</strong>。也就是说，并没有跨Project的复制，而是从源Project把文件复制出去。</p>

<h3>自动编译</h3>

<p>IntelliJ默认是不会自动编译项目的，所以在run之前会有个make的过程，习惯自动编译项目的可以在这里打开：Compiler=>make project automatically。因为IntelliJ项目空间不大，所以开启之后也不会像Eclipse一样出现build workspace很久的情况。</p>

<h3>Debug</h3>

<p>debug最好不要使用method breakpoint，会导致启动异常缓慢，博主之前就不小心启动了method breakpoint，然后进入调试要花掉几分钟的时间。IntelliJ断点可以设置Condition，其实Eclipse也可以，只不过没有这么明显，同时IntelliJ可以在Condition进行代码提示。</p>

<h3>File Template</h3>

<p>与Eclipse的Code Template类似，只不过IntelliJ内置变量全部为大写，例如：${NAME}。可以使用#parse(&ldquo;File Header.java&rdquo;)这种格式来导入另一个文件，跟jsp include的作用一样，实现复用的一种方式吧。没有导入/导出，有点不太方便。</p>

<h3>Live Template</h3>

<p>用惯了Eclipse快捷键的人可能会不习惯，sysout、foreach等快捷方式找不到了，main方法也无法自动补全了，其实这个在IntelliJ中有一个异常强大的模块Live Template来实现。</p>

<p>例如，在class中尝试psvm+tab，则会发现main方法产生了；输入iter+tab，则生成了foreach语句。
live template还有一个surround的用法，选中某个变量，键入ctl+alt+j两次，则会出现自动补全的菜单。</p>

<p>此外，还可以自定义Live Template。Code Snippet技术应用也挺普遍的，IntelliJ的Live Template优点是内置了一些智能的变量和函数，可以做到一些语义级别的分析和运用。</p>

<hr />

<h3>几句牢骚</h3>

<p>IDE的圣战从来没有停止过，Eclipse还是IntelliJ好？首先，IntelliJ某些更加体贴的功能，让我感叹一分钱一份货。比如选中括号的后面部分，即使滑动到了下一屏，也会将括号开始的部分浮动显示出来。更重要的，我想引用一下《大教堂与集市》中的比喻，Eclipse好比集市，有开放的环境，本身功能并不求全责备，通过插件来提供相应的功能(最基本的maven、VCS都需要第三方插件提供)。相对的，IntelliJ就像大教堂，内部整合了大多数功能，基本上是一体化的使用设计。</p>

<p>庞大的插件机制和依赖也使得Eclipse出现一些混乱和不稳定。插件依赖/兼容性/稳定性都存在一些问题，而且Eclipse一味向可扩展设计的方式也使得使用起来会更复杂。例如，Eclipse的快捷键设置功能，全部是一字平铺，有一个&#8221;when&#8221;的选项，我理解这是使用快捷键的一个场景。问题是，所有插件都可以向它注册一个场景，当我真要选择when的时候，发现列表有两页之长，我哪知道选哪个？相反，IntelliJ的keymap采用了分类的方式，一级分类就是使用场景，然后再进入相应项设置快捷键，比Eclipse方便的多。再比如，有人说Eclipse慢，其实很可能并不是内核慢，而是一些插件(例如m2e)运行太慢导致的。而IntelliJ基本上都是很迅速的，很少出现失去响应的情况。</p>

<p>这里我想引用一篇文章《有人负责，才有质量：写给在集市中迷失的一代》<a href="http://www.oschina.net/news/32190/a-generation-list-in-the-bazaar">http://www.oschina.net/news/32190/a-generation-list-in-the-bazaar</a>。Eclipse庞大的体系注定了插件管理的松散性，所以使用者就要忍受一些不稳定和不方便的因素。相比IntelliJ，因为是公司开发，大部分插件都在其管理范围之内，所以整体质量更好控制。</p>

<p>说到这里好像就认定IntelliJ好了？其实也未必，因为《大教堂与集市》也提到，开源带来的生产力是教堂式开发远不能比的，所以IntelliJ要收费，而Eclipse可以免费。Eclipse庞大的插件群，功能的全面性，个人觉得也是IntelliJ比不了的。</p>

<p>最后说一句，说到学习成本，其实IntelliJ是要比Eclipse低的，至少省去了很多配置插件、理清依赖、处理问题的功夫，同时设置也比Eclipse要简单不少。没有说越高级的IDE越复杂的说法，只是Eclipse作为最常用的Java IDE，让大家先入为主了罢了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[BlackHole开发日记-使用三种不同IO模型实现一个DNS代理服务器]]></title>
    <link href="http://code4craft.github.com/blog/2013/04/12/blackhole-io-model/"/>
    <updated>2013-04-12T22:16:00+08:00</updated>
    <id>http://code4craft.github.com/blog/2013/04/12/blackhole-io-model</id>
    <content type="html"><![CDATA[<p>BlackHoleJ是一个DNS服务器。他的一个功能是，对于它解析不了的DNS请求，它将请求转发到另外一台DNS服务器，然后再将其响应返回给客户端，起到一个DNS代理的作用。</p>

<p><img src="http://code4craft.github.com/images/posts/forward.png" alt="image" /></p>

<p>这个功能的实现经历了三个版本，也对应了三个经典的IO模型。</p>

<!-- more -->


<h3>BIO模型(Blocking I/O)</h3>

<p>BlackHoleJ代理模式最开始的IO模型，实现很简单，当client请求过来时，新建一个线程处理，然后再线程中调用DatagramChannel发送UDP包，同时阻塞等待，最后接收到结果后返回。</p>

<pre><code>public byte[] forward(byte[] query) throws IOException {
    DatagramChannel dc = null;
    dc = DatagramChannel.open();
    SocketAddress address = new InetSocketAddress(configure.getDnsHost(),
            Configure.DNS_PORT);
    dc.connect(address);
    ByteBuffer bb = ByteBuffer.allocate(512);
    bb.put(query);
    bb.flip();
    dc.send(bb, address);
    bb.clear();
    dc.receive(bb);
    bb.flip();
    byte[] copyOfRange = Arrays.copyOfRange(bb.array(), 0, 512);
    return copyOfRange;
}
</code></pre>

<p>其中dc.receive(bb)一步是阻塞的。因为请求外部DNS服务器往往耗时较长，所以为了达到快速响应，不得不开很多线程进行处理。同时每个线程都需要进行轮询dc.receive(bb)是否可用，会消耗更多CPU资源。</p>

<h3>Select模型(I/O multiplexing)</h3>

<p>BlackHoleJ 1.1开始使用的IO模型。因为DNS使用UDP协议，而UDP其实是无连接的，所以所有请求以及响应复用一个DatagramChannel也毫无问题。同时预先使用DatagramChannel.bind(port)绑定某端口，那么对外部DNS服务器的转发和接收都可以使用这个端口。唯一需要做的就是通过DNS包的特征，来判断到底是哪个客户端的请求！而这个特征也很好选择，DNS包的headerId和question域即可满足需求。</p>

<p>发送方的伪代码大概是这样：</p>

<pre><code>public byte[] forward(byte[] queryBytes) {
    multiUDPReceiver.putForwardAnswer(query, forwardAnswer);
    forward(queryBytes);
    forwardAnswer.getLock.getCondition().await();
    return answer.getAnswer();
}
</code></pre>

<p>接收方是一个独立的线程，代码大概是这样的：</p>

<pre><code>public void receive() {
    ByteBuffer byteBuffer = ByteBuffer.allocate(512);
    while (true) {
        datagramChannel.receive(byteBuffer);
        final byte[] answer = Arrays.copyOfRange(byteBuffer.array(), 0, 512);
        getForwardAnswer(answer).setAnswer(answer);
        getForwardAnswer(answer).getLock.getCondition().notify();
    }
}
</code></pre>

<p>这里forwardAnswer是一个包含了响应结果和一个锁的对象(这里用到了Java的Condition.wait&amp;notify机制，从而使阻塞线程交出控制权，避免更多CPU轮询)。还有一部分是multiUDPReceiver。这里multiUDPReceiver.putForwardAnswer(query, forwardAnswer)实际上是把forwardAnswer注册到一个Map里。</p>

<p>这样做的好处是仅仅在一个线程检查原本的多路I/O是否就绪，也就是I/O multiplexing。这跟Linux下select模型是一样的。</p>

<h3>AIO模型(Asynchronous I/O)</h3>

<p>BlackHoleJ 1.1.3开始，使用了基于回调的AIO模型。这里建立了UDPConnectionResponser对象，里面封装了client的IP和来源端口号。每次收到外部DNS响应时，再根据响应内容找到这个client的IP和来源端口号，重新发送即可。</p>

<p>这实际上就是封装了callback的异步IO。</p>

<p><img src="http://code4craft.github.com/images/posts/aio.png" alt="image" /></p>

<p>发送方的伪代码大概是这样：</p>

<pre><code>public void forward(byte[] queryBytes) {
    multiUDPReceiver.putForwardAnswer(query, forwardAnswer);
    forward(queryBytes);
}
</code></pre>

<p>接收方的代码大概是这样：</p>

<pre><code>public void receive() {
    ByteBuffer byteBuffer = ByteBuffer.allocate(512);
    while (true) {
        datagramChannel.receive(byteBuffer);
        final byte[] answer = Arrays.copyOfRange(byteBuffer.array(), 0, 512);
        getForwardAnswer(answer).getResponser().response(answer);
    }
}
</code></pre>

<p>这里getResponser().response()直接将结果返回给客户端。</p>

<h3>测试：</h3>

<p>使用queryperf进行了测试，使用AIO模型之后，仅仅单线程就达到了40000qps，比1.1.2效率高出了25%，而CPU开销却有了降低。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[2012年总结]]></title>
    <link href="http://code4craft.github.com/blog/2013/02/25/2012-summary/"/>
    <updated>2013-02-25T22:40:00+08:00</updated>
    <id>http://code4craft.github.com/blog/2013/02/25/2012-summary</id>
    <content type="html"><![CDATA[<p>看了别人写的数字总结，自己也来跟风写一个吧。</p>

<p>看了8本书：</p>

<p>《HTTP权威指南》、《UNIX编程艺术》、《程序员的思维修炼》、《软件随想录》、《TCP/IP详解》、《构建高性能Web站点 : 改善性能和扩展规模的具体做法》、《深入Java虚拟机》、《JAVA并发编程实战》</p>

<!-- more -->


<p>学了一门语言：python。</p>

<p>阅读3个项目源码：JDK集合框架和锁框架，qmail源码，JavaMail源码。</p>

<p>Java web后端开发学到技术：</p>

<p>Struts2 iBatis SpringAOP</p>

<p>做了3个得意的业余项目：可配置博客搬家、BlackHole、太极验证码。</p>

<p>写了45篇技术相关的博客，内容的质量比起2011年有了很大提高。</p>

<p>参加了两次20人左右的演讲。</p>

<p>完成了一个大项目：邮件重构，参与者7人。</p>

<p>买了一个域名codecraft.us，做了一个网站。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[BlackHole开发日志--防止DNS污染]]></title>
    <link href="http://code4craft.github.com/blog/2013/02/25/blackhole-anti-dns-poison/"/>
    <updated>2013-02-25T21:13:00+08:00</updated>
    <id>http://code4craft.github.com/blog/2013/02/25/blackhole-anti-dns-poison</id>
    <content type="html"><![CDATA[<h3></h3>

<hr />

<h3>DNS污染原理</h3>

<p>DNS污染是比DNS劫持更加难以防御的一种攻击，受攻击者访问网站时可被导向其他域名，例如某“不存在的网站”被导向了一个“不存在的IP地址”。</p>

<p>DNS污染的原理如下：</p>

<p>DNS查询也是一个经典的请求-回答模式。首先，客户端发起DNS查询，这是一个UDP包。路由器在转发IP包时，对其内容做解析，若发现其是使用53端口的UDP包，并且其内容符合某些特征(普通的DNS请求都是明文)，则从旁路直接返回一个伪造的应答，将其应答指向某个特定IP。因为这个返回速度非常快，所以先于正常请求到达客户端。而客户端收到一个返回包，就认为得到了答案，不再继续接收，而正确的请求结果就被忽略了！</p>

<p><img src="http://code4craft.github.com/images/posts/dns-poison.png" alt="image" /></p>

<!-- more -->


<p>一般防止DNS污染有几种方法：</p>

<ul>
<li><p>修改系统hosts文件</p>

<p>  系统的hosts文件可以配置某个域名对于的IP地址，并且会优先于DNS服务器的响应，所以此方法稳定高效，缺点是host地址需要不断更新。</p></li>
<li><p>改用TCP协议而不是DNS协议发送DNS请求</p>

<p>  DNS也支持TCP协议传输，而TCP协议没有收到污染，所以可以改用TCP作为DNS下层协议。缺点是TCP速度慢，并且DNS服务器支持度有限。代表工具：Tcp-DNS-proxy <a href="https://github.com/henices/Tcp-DNS-proxy">https://github.com/henices/Tcp-DNS-proxy</a></p></li>
<li><p>使用IPv6地址发送DNS请求</p>

<p>  某些站点可以通过IPv6地址访问。代表工具：dnsproxycn <a href="http://code.google.com/p/dnsproxycn/">http://code.google.com/p/dnsproxycn/</a></p></li>
<li><p>根据污染特征过滤伪造DNS答案</p>

<p>  先截获DNS污染结果，然后分析其特征，然后将判断为污染的DNS包过滤掉。代表工具：AntiDnsPollution <a href="http://www.williamlong.info/archives/2184.html">http://www.williamlong.info/archives/2184.html</a></p></li>
</ul>


<h3>BlackHole解决方案</h3>

<p>BlackHole解决方案是第4种：向一个不存在的地址发送DNS查询，正常情况下不会有应答；若触发DNS污染，则只会有伪造包返回。记录这个伪造包的特征(一般是A记录的IP地址)，加入黑名单，下次如果收到这些包，则直接过滤。</p>

<p>其实开发BlackHole时不知道有AntiDnsPollution这款工具，完成了才知道，采取的方法不谋而合。只不过BlackHole做的更复杂一点，增加了一些功能：</p>

<ul>
<li><p>DNS污染黑名单持久化</p>

<p>  所有污染IP都会存入&#8221;安装路径/blacklist&#8221;文件，每次重启可继续读入，也支持手工修改。</p></li>
<li><p>可用IP导出host</p>

<p>  BlackHole会对IP地址做可达性判断(根据ICMP协议请求)，存在DNS污染的域名，若正确DNS地址中，同时有可达IP，则会产生一条&#8221;IP domain&#8221;的DNS记录到&#8221;安装路径/safebox&#8221;文件中，与hosts文件格式一致，可以粘贴进去，从而无须再启动BlackHole。</p></li>
<li><p>支持多DNS服务器请求</p>

<p>  BlackHole可以同时向多个DNS服务器请求，并采用最先返回的正确结果作为答案返回；同时后台会继续接收响应，并根据最终答案中IP地址的可用性进行判断，去掉不可用的IP。你可以将BlackHole的转发DNS配置为：一个ISP提供的服务器，速度较快；另一个权威的DNS服务器，结果较可信。对于大多数请求，ISP提供的DNS可以满足需要，从而降低查找时间。同时如果在公司内网中使用，还可以将公司内部DNS服务器地址配置进去，这样可以保证内部配置的某些DNS的有效性。</p></li>
<li><p>支持缓存</p>

<p>  BlackHole使用ehcache作为缓存，并且可以持久化，下次启动时可直接载入上次缓存结果。</p></li>
<li><p>可配置</p>

<p>  BlackHole还是修改hosts文件的替代方案。通过修改&#8221;config/zones&#8221;可以自定义DNS拦截规则，支持通配符&#8221;*&ldquo;。</p></li>
</ul>


<p>BlackHole的源码地址：<a href="https://github.com/code4craft/blackhole">https://github.com/code4craft/blackhole</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[十年莽撞IT路]]></title>
    <link href="http://code4craft.github.com/blog/2013/02/17/fenng-career/"/>
    <updated>2013-02-17T18:39:00+08:00</updated>
    <id>http://code4craft.github.com/blog/2013/02/17/fenng-career</id>
    <content type="html"><![CDATA[<p>原文地址：<a href="http://dbanotes.net/mylife/ten_years_it_road.html">http://dbanotes.net/mylife/ten_years_it_road.html</a> 作者冯大辉<a href="http://weibo.com/fenng">@fenng</a></p>

<!-- more -->


<p>按：博文视点周筠老师多次叮嘱我写点关于个人成长的心得，颇感压力。回首在 IT 这个行业也差不多有 10 年了，在互联网也有 7 年之久，没做成什么惊人的事业，也没什么赚到大把的钞票，如果冒充什么成功导师大谈人生感悟岂不是会被读者朋友笑掉大牙，当然引来板砖也说不定。如果说有可取的，恐怕也就是自己莽撞的混入这个行业阴差阳错的一路走过来，有些教训或许能供朋友们参考一下。所以，硬着头皮记录一下过去几年的流水账。是为序。</p>

<h3>唯一幸运的事情</h3>

<p>我是东北人，家乡是一个产粮大县，周围上百里都是平原，一望无际的玉米田，春耕秋收的时候倒也非常漂亮。只是小的时候家乡经济并不发达，回想起来仍然没多少好感。从小到大，没吃过什么苦，没享过什么福。小学的时候，有幸遇到了一位很好的启蒙老师，很大程度上启发了我的思维，让我终身受益，现在想起来，真的要感谢他！这么多年回顾一下，我有很多运气不错的时候，比如初中升高中，全校几百个学生，我是唯一一个进入我们这个县级市重点高中的（可想而知教育质量如何之差）。这并不是我如何刻苦或是如何聪慧，只是带着偶然性的幸运而已。至于在 1997 年能被保送上大学，说来也很巧，那一届的同学里其实有一些有力的竞争者，但我是属于平时学习成绩还算相当不错的，而且会考成绩全部优秀，在当时的班主任郑老师的据理力争之下，居然最终保送成功。我曾经一度怀疑是不是自己家里背着我走了后门托了关系，很遗憾，最后证据不足，因为我们家经济上没有实力，也确实没有这方面的关系。只能归结为运气较好，当然还要感谢我的老师对我青眼有加。</p>

<p>我不知道如果我参加了高考人生会怎样？当时的高考是千军万马过独木桥，远非现在这样上大学这么容易。而我尽管其它科目成绩都不错，但是物理成绩是忽高忽低，我之所以走另一条「安全系数」高一点的路，多少也是出于这个担心。没能参加过高考对我来说是一件非常遗憾的事情，以至于好些年经常做梦都是马上要进行高考，或是满头大汗的在答题，然后在惊慌中醒来。扯远了，确定了自己被录取之后，和周围的同学相比，我一下子多出来几个月的空闲时间，非常悠闲的时光，着实看了不少书。我从很小的时候养成了阅读的习惯，只是限于条件，找不到太多的有趣的书可以读，这次算是弥补一下。在我养成的习惯中，可能阅读是唯一的为数不多的好习惯之，这么多年以来，我每年总要给自己留点空闲时间读书，真的是一种乐趣。</p>

<p>很多朋友应该知道我大学的专业学的是生物学，有的时候我说是生物技术。其实到现在我也不知道，我的大学专业到底应该怎么界定，因为我们的班级叫做「生物基地班」，隶属于「国家理科基础科学研究和教学人才培养基地」，听起来挺高端的，当时全国这样的班级并不多，我当初是学校的第一批。在上大学之前并不知道自己对生物兴趣有多大，只是当时只有两个选择，要么选择历史，要么选择生物，考虑到历史属于文科，选择生物似乎更适合一个理科学生，家里对这个也没有多大的意见。当时影响这个选择的是上一年和生物有关的一件轰动世界的大事：克隆羊多莉的诞生。报刊杂志上都是相关的报道。想到自己以后有可能做这方面的事情，还是很令人兴奋的。我甚至还给面试我的老师介绍了一下什么是克隆。当时，我并不知道自己的一些选择会影响我今后人生的道路。</p>

<p>到了大学以后才发现自己并不喜欢这个专业，生物学中有些基础课程是需要死记硬背的，开始的时候还可以硬着头皮将就一下，到后来就随心所欲了，专业课的时候神游天外，到了考试之前才去临阵突击。遗憾的是，这个时候我意识到自己的确并非什么天才，短时间的冲刺根本解决不了什么问题，当然，结果也不是非常的差。但这样下去终归不是问题，大学二年级的时候，干脆选择了逃避，我偷着联系了历史系的基地班，要转系「跳槽」过去，一时间，引起了学院内的轩然大波，因为这是前所未有的事情，再说，所有人都觉得我们这个专业相当的不错，为什么会有人要走？这不是也丢了院系的面子吗？经过系里的老师苦口婆心的劝说，最后我终于洗心革面，答应老师，要好好学习专业课。总算是暂时平静了下来。经过这一次的折腾，自己的「空间」似乎大了一些。去系里的计算机室似乎受到的约束甚至也小了许多。因为属于教育基地班的缘故，当时院系斥巨资兴建了一个计算机室，配备的是 486 的机器，少数是 586 的机器。和我同期前后上大学的朋友应该对当时那种计算机房还有印象，进来都是要穿鞋套的，还要登记什么的，而我们系看管计算机房的老师似乎生怕学生把计算机捣鼓坏了，整天象防贼一样防备着学生多占用上机时间。这个老师肯定也听说过摩尔定律，但他肯定不知道如何提升计算机的利用率，不知道如何发挥计算机的最大价值。在我们毕业的时候，那个机房已几乎无人问津了–因为机器相比之下都太古老了。</p>

<p>{据说，这么多年之后，我已经是学院里的一个异类的传说，很多老师会把我当作一个典型的例子，不好好学习专业也能做点对社会有用的事情，也让师弟们获得了一点空间。}</p>

<p>我在上大学前没怎么接触过计算机，那时候周围的同学中有机会接触计算机的，要么是家庭条件相当好的，要么是游戏迷，幸运的是，当时在电脑上玩游戏的价格对我来说过于昂贵。到了大学有了接触计算机的条件，我当时的兴趣应该也并不是最狂热的，只是好玩而已。因为开的计算机课程都是一些基本的概念，二进制什么的，编程课是 BASIC，老师其实也并没有讲多少内容。上机的时候，我最喜欢做的一件事情大家肯定猜不到：用 Windows 自带的画图程序描摹蔡志忠的漫画。BASIC 我到现在也不喜欢这个语言，总感觉接触不到底层，或许是我的性格使然。当时的计算机图书，谭浩强的大作几乎就是教科书的代名词，遗憾的是，他的C语言的教材，就像是他那本 BASIC 教材用 C 语言翻译了一下。非常偶然的一个机会，在图书馆看到一位师兄拿着一本 Linux 的书，我在图书馆多次看过 Unix 的书籍，苦于周围没有相关的环境没办法深入学习，而 Linux 这个词不知为什么让我印象很深，以至于回到宿舍我还和同学说起来这个事儿。很快，国内陆陆续续有更多关于 Linux 的报道了，而且，可以买到系统介质光盘了，这样就可以偷着在一些机房安装起来，然后偷着练习一会儿。尽管这样，实践的机会仍然比较少，以至于很多 Unix 下的东西，我都是背下来的。现在回想起来，也真够费劲的。我最不能原谅学校的一点就是学生宿舍用电实在是太「节能」了，每天 10 点半熄灯，而且电压还不够，想弄一台电脑放在宿舍内也不可能。至今想起来仍让人愤懑。不知道现在怎么样了，好像还是老样子。有些陈腐的观念，十年前和现在并无不同。</p>

<p>说这些并不是强调我对计算机有多么热爱，对我来说，只是感觉这是一种能够谋生的可能，而且，还比较有趣，对我更有趣的事情无疑更多，但不是所有有趣的事情都能变成一种职业。所以，选择计算机，至少比我所学的生物学要有更大的可行性。现在回想起来，当时所有人都说生物学是21世纪最有前途的学科，我想，那也有可能是 21 世纪后 20 年才会发生的事儿吧，我没有办法等到那一天。</p>

<p>相比在计算机上投入的时间，可能我花在听音乐上的时间更多。可能摇滚算是一个愤青的标配了吧？在大学里我是中国摇滚乐的死忠支持者，四年下来，为了这个爱好倒是耗费了我不少饭钱。但很明显，在中国做音乐很难让你吃饱饭（可能这一两年好了不少)。另外，音乐这东西除了所谓的灵感之外，必须要足够时间的磨练才可以,所谓一万个小时的训练。这么多年回头看看，那帮摇滚人的确不争气，和这个国家一样，挺让人失望的。现在很多音乐人一出场就「同一首歌」的范儿，偶尔看到让人不胜唏嘘 — 这群人不是挺有性格的嘛，怎么都混成了这个样。</p>

<p>互联网对我的影响是逐渐发生的，第一次接触互联网应该是在 1998 年，并没有有其他人说的那种「震撼」的感觉－因为速度实在是太慢了。直到后来自学计算机的过程中通过网络查找各种资料（当然上网费用也逐渐降了下来），才一点点的体会网络的妙处。互联网对我这样的穷孩子来说，是一种信息上的解放。网络让我看到了一个更为辽阔，甚至可以无限延伸的世界，使得我了解到更多荒谬但是又现实的东西，使我认识到更多的可能从而突破自身的障碍，我想我的人生观应该是在这个时候逐渐形成的。如果没有互联网，我会成为一名误人子弟的教师？或是一个不合格的工程师？不管怎样，不会是现在的我。从某种意义上说，我自己，我们这一代人都应该感谢互联网，而能接触到互联网是我们这一代人唯一真正幸运的一件事。</p>

<p>每当被《程序员》杂志约稿的时候，我都要提醒一下自己：我不是程序员。这是真心话，我没有做过一天真正意义上的程序员，尽管我非常想做。我不太喜欢程序员自嘲称自己为「IT民工」或是「码农」什么的，总觉得做这个行业，就要尊重自己的职业才是。我自己并非计算机的科班出身，在大学里也没能积累下足够多的写代码的经验，毕业求职的时候其实是没办法竞争编程开发相关的岗位的，只能走差异化竞争的路线。万幸的是，我认识到IT行业除了开发程其实还有工作岗位可以选择。所以，较早的逆向推演自己能够做哪些事情，并且结合自己的兴趣，在操作系统(Unix)的实践和网络(比如TCP/IP)理论方面下了一番苦功夫，加上一些机缘巧合，最后能够有幸撞入这个行当。在 2000 年左右的时候，专业歧视还是蛮严重的，那个时候几乎绝大多数 IT 公司的校园招聘都会比较严格的限定专业，而像我这样从八竿子打不着的生物学要跨入IT行业的，基本上很少有人理睬。我想我永远都会感谢给我机会的那位面试官。</p>

<p>我只参加了两次招聘宣讲，第一家是华为，但华为根本不看我们这些八竿子打不着的专业来的人。没有应聘上华为，对我来说也是一件幸运的事情，我的个性散漫，在华为这种半军事化管理的公司里面，肯定会闷死。第二次去参加招聘宣讲，完全是抱着领取奖品的心态去的 — 宣讲会上有可能发放 Linux 资料和光盘。很多人递简历给面试官的时候，我发现自己根本没戏，面对科班出身的同学，随便问几个关于数据结构的问题我也不可能比别人回答的好。于是在旁边站着。恰好，有一位女面试官也在旁边站着。</p>

<p>「您也是面试官？请你看看我的简历吧！」 「你为什么不到那边投简历？」 （指排队递交简历的地方） 「那边不可能要我，我不是学这个的。」 「那你为什么还来？」 「我会点别的东西。」 「都有哪些呢？」 「Unix 和 Linux 自己学了很久，TCP/IP 也会点。」 「那你说出10个Unix命令给我」 「这个容易，(说了一堆）」 「再说说 Unix 的各个运行级是怎么回事？」 「（我又说了一堆）」 「嗯，好像真的学过，今天来面试的好像还真没有对这些感兴趣的人…再说说 TCP？」</p>

<p>就这样，这就是我第一份工作的最主要的面试环节(时间久远，细节上可能稍有差异)。我毕业求职没有很高的目标，但对自己有两个基本的要求：到北京工作， 从事 IT 行业。没想到，比我预想的要顺利不少。</p>

<p>招聘我的公司是个中字头的国企，有着较为荣耀的历史，在当时来看，整体上是一家大公司，但具体到每一家分公司，则是不折不扣的小公司，当然也谈不上什么好的公司文化。因为毕业之前没有和公司联系，所以也没有到公司实习，毕业后直接就直接到北京来报到了，行政人员还为是否留下我这个人作了一番斟酌，想来也挺有趣。我们这几个毕业生的岗位是系统工程师，说的直接一些，其实也就是一些 Unix 下的软件的安装和实施，需要到各地出差，对于刚走出校园、毕业前甚至没有出过东三省的我也是一种很好的锻炼，可以了解一下各地的风土人情。这段工作也磨练了我与人打交道的能力，尽管做的还不够好–还不能很好的控制自己的脾气，当然暗地里也吃过不少亏。</p>

<p>没有项目的时候，有大量的时间和几个同事一起学习和实践。就是在这家公司，我在 Unix 操作系统之外，开始选择数据库作为一个学习方向。没有人告诉我应该做 什么样的选择，说老实话，只是看当时招聘数据库管理员的公司给开出的薪水的确都很不错，就误打误撞开始了数年的数据库技术之路。国内当时也出现了一个面向数据库技术的网络论坛，ITPub.net，聚集了一大批数据库技术的爱好者，大家在论坛上分享资料，交流心得，不亦乐乎，结识了不少朋友。如前所述，正是互联网给了我们学习更多知识的可能，否则，只有在具体的应用场景才有可能接触到这些，我也走不到今天。</p>

<p>在这家公司工作了一年多，感觉自己的数据库有了一点基础，能力有了提高，就冒着极大的”风险”跳槽了。说是风险，因为公司的母公司隶属国企，每个毕业生都签署了四年的合同，如果提前离职要对公司进行赔偿，合同上写明总计 2 万五千元，对当时的我来说，这是一笔巨款。当然现在想可能也没什么。对当时的我来说，倍感压力，有点杨白劳遇上黄世仁的感觉。我想现在的毕业生应该很少再面对这种霸王条款了吧。有朋友会说，毕业一年就跳槽，太对不起这家公司了吧？对当时的我，其实也是不得已而为之，加上当时也不是很懂事。</p>

<h3>数据库</h3>

<p>很多朋友知道我，是因为我的曾经在 DBA 这个岗位工作过很久，实际上，我走向 DBA 的岗位径并非一帆风顺的，甚至稍有一些周折。我新入职的这家公司隶属于一家更大的国企期，公司的负责人雄心勃勃，组建了一只不小的数据库技术团队，主攻电信行业商业智能的市场。遗憾的是，最后在商务上并不理想，而项目实施也出现了不小的问题，当然，那是在我离开之后的事情了。在这个团队我只工作了半年左右的时间，并不顺利，也并不开心。问题主要是出在我自己身上，和直接主管的沟通总是有问题，遗憾的是，我当时甚至不认为自己有问题，这是很多初入职场的人的通病，也或许是很多人的通病－总喜欢把责任推在别人身上，而无知的认为自己没有错。我在这家公司的一个收获是看到了余世维的一个讲座视频，应该是给某电信企业做的培训课程吧。虽然现在看，这一套成功学的东西其实没什么可取之处，但当时给我的感觉还是挺震撼的。因为此前，我从来没有考虑过如何修正自身的一些问题。</p>

<p>从这家公司离开后，在接下来的这家公司的经历则颇有戏剧性，我作为数据库管理员入职后没多久正好赶上非典爆发，第一次享受在家里远程办公的乐趣，非典过后上班第一天得知，老板居然把公司卖掉了，就这样，没做什么事情，拿了几个月工资，但是自己好像没赚到什么便宜。考虑到公司并入新的公司后发展方向对自己并不有利，这是一件完全以销售为主导的公司，技术人员只需要做项目实施即可，到处出差，对着说明文档敲命令，时间长了必然会索然无味。所以不得不考虑再次换一份工作。其实这个时候对我自己来说，已经有些苦恼了，我知道频繁的更换工作对一个人的发展的负面影响是很大的，尤其是在刚进入这个行业不到两年的情况下。所幸自己还没有完全进入舒适区，继续的选择不需要太大的挣扎。</p>

<p>我下决心，无论如何下一个工作要更为长久一些。</p>

<p>很快，又找到了一家公司。新的公司规模不大，但总也是一家外企，老板是韩国人，有美国留学的背景。能够进入外企可能是那个时候很多人的一个阶段性目标，怎么说呢，至少我在当时还是很羡慕一些在外企工作的朋友，起码薪水很不错。这个时候，谁有那么长远的眼光不在乎薪水呢？甚至也很少有过来人跟你讲关于发展与职业规划这些事情，基本上是凭着感觉走，只能多观察，多分析别人的经验（网络上有不少过来人会写自己的职业历程，不需要问他们，阅读，分析，进一步对比自己，了解自己，这就足够了）。新公司同事都很有活力，大家关系相处的也都不错。公司制度也比较灵活，我甚至有的时候中午才去公司上班。当然，公司给出了空间，工作起来也都是挺卖力的。</p>

<p>这家公司有两个业务方向，一块是给联通做增值服务，我的工作职责包括在这一部分；另一块是开发手机上的浏览器，这是公司发展的重点，大部分同事也都是做开发的。先在回想起来，这个浏览器太超前了，当时是2004年左右，手机根本没有发展到这个地步，而且，单靠这一款软件，没有上下游的产品支撑，尽管也有想象力，但最后还是没有合适的出路。一年多之后，公司启动了另一个产品，一个在线音乐网站。这个也是老板借鉴韩国的互联网的模式做出的决定。很显然，结局不猜也会知道，这也是个失败的项目。我想起来这个项目甚至有些后悔，错失了一个很好的锻炼机会，如果当初能够多承担一点点责任的话，或许能做得更好也说不定。</p>

<p>我是在加入这家公司之初开始更多的关注起互联网技术，搭建了自己的个人站点，后来尝试写起了 Blog，通过捣鼓（真的是捣鼓）个人站点，一点点的摸索、学习到了更多的东西。我对Web相关的一些技术没有系统的学习过，只是时间长了形成了感觉而已。早期 Blog 技术圈子都是一些很纯粹的技术爱好者，更多的人只是为了分享而写作，为了乐趣而写作。我自己差不多也是这样，学习搭建站点，学习如何写技术文档，首先写的东西要对自己有用，以这个为标准，逐步发现对别人也有点用，进而得到一些正面反馈（也会满足自己的一点的虚荣心），继续总结，继续写，慢慢的，尝试写一些自己不太熟悉的技术领域的分析笔记，记录，总结，时间久了，也就形成一种习惯了。</p>

<p>通过 Blog 这个途径，我慢慢结识了另外的一个技术群体。做我们这个行当的技术人员总会抱怨没什么前途，没什么空间，根据我的观察，社交面太小也是对很多人的一个制约。当你社交面逐渐打开的时候，接触的信息也会越来越多，所谓的机会，其实是相当多的。如果不擅长在那种传统的社交方式，而网络就是技术人员最好的社交媒介。</p>

<h3>杭州阿里五年</h3>

<p>在2004年的时候，一位素未谋面，但是在社区内打过不少交道的朋友邀我加入阿里巴巴，刚刚启动的支付宝数据库没有人维护，服务器压力也不大，哎呀，非常的吸引我。尽管上一年也有类似的机会，但当时感觉一是自己技术未必能撑起来，二是薪酬似乎也很一般，再者阿里巴巴当时的声誉并非很好（竞争对手散布了很多妖魔化阿里巴巴的信息）。经过一年后，我面对这个邀请，忽然觉得可能是个机会，毕竟再一再二不能再三阿，万一错过了呢？去看看也不会损失什么，而且阿里数据库团队已经拥有好几位技术社区上的牛人了，能吸引这么多人才本身也说明公司里肯定有自己的特点。</p>

<p>杭州一行，整个接触下来感觉这帮家伙都太有趣了，坚定了自己「南下」的决心。马云在2004年底发表过一个言论，「2005年将是中国电子商务安全支付年」，让我很受触动，想想做的事情有可能给互联网带来一些改变，那将是让人多么欣喜的事情，一时间我对杭州的这份新工作充满憧憬。另外，当时我对浙江的商业气氛也很感兴趣，「在那边工作几年，学习一下浙江人怎么做生意，然后再回北京」，我用这个说辞说服了女朋友，我现在的太太。</p>

<p>到了杭州之后工作就上了快车道。支付宝当时正面临着一次相当大的业务改造，为了避免对用户的影响，很多操作都要夜里进行，白天还要支持开发团队，前三个月的工作强度之大让我始料未及，又不能临阵逃脱，只能硬扛。到了项目发布之前的时候，连续几个通宵人都熬不住了。正式发布那天遇到了大麻烦悲剧来临，因为之前赶进度而忽视了性能方面的问题，导致发布的时候恰恰性能问题成了拦路虎，整个技术团队都在后面看着你呢，让人一筹莫展，这种情况下要承受的压力可想而知。让我至今感激的是，团队里的其它几位同事在我撑不住的时候顶了上来，直到最后系统上线，大家终于松了一口气。我不知道有多少人在工作中面临过类似的压力，那段时间，每天早晨起床后，我告诉自己，坚持过今天就好了…就这样，一点点的熬了过来。这就像爬山一样，在你非常累的时候，继续向前走几步，再继续走…也就到了山顶。在以后的几年，我甚至遇到更大的压力，但因为有前面的铺垫，心理抗压能力已经加强了许多，反而会逐渐享受这个过程。一旦进入IT这个行业，早晚都会遇到你职业生涯中的种种看似跃不过去的障碍，我所能给出的建议也无非就是「再坚持一下，不知不觉就跨过去了」。</p>

<p>这段时间我甚至强化了另外一个习惯－阅读。每当压力巨大的时候，为了能不失眠，需要切换一下思维，临睡前就强迫自己看一会儿小说，效果还真不错。我不知道自己什么时候练成了快速阅读的能力，应该是长期积累下来的吧，我坚信只要读的足够块，就可以读到更多的东西，有的值得再次阅读的，反复阅读。小的时候接触不到太多的可以看读的东西，所以有些书籍甚至会读个几十遍，最多的一本书恐怕足有上百遍了吧。到了读大学的时候，有了更大的阅读空间，我成了同学中到图书馆借书最勤快的人，以至于到后来图书馆管理员都认识我了，当然还省吃俭用买了更多的书，包括学习一些新技术的时候，我的一个习惯也是会多买几本书对照着看阅读，对我自己来说，收效还是不错的。我比较喜欢有阅读习惯的技术人，当我面试的时候，如果一个技术人很长时间都没有读过一本书，会让我降低对他的评估分数，当然，这是我的个人偏见而已。 应该说，对于我而言说，阅读是一种乐趣，和有些人喜欢电子游戏是一样的。</p>

<p>在杭州的前三年，为工作牺牲了自己的不少量业余时间（正常的工作时间有的时候反而比较空闲，所以，才有可能写一些文章），因为公司随时可能有事情，而且，有事情就不会是小事情，大多数业务都直接涉及到资金数据，稍有不慎，可能就会酿成大祸。我现在非常怀念和同事们通宵发布的那些日子，的确非常辛苦，但其中也有莫大的乐趣。每当即将拂晓的时候，在崔健的音乐声中，看着窗外的渐渐清晰景色，总让人有一种莫名的欣喜，好像我们每个人的前途都光明起来。</p>

<p>公司的业务实在发展的太快，技术要想不拖业务的后腿，也只有跑的更快，这也是那几年我在技术上有点进步的一个主要原因，强迫自己做更多的事情。慢慢的在工作中我意识到，要更好的提供后端的数据支撑能力，不理解整体的技术架构是不行的，这是我开始学习Web架构方面知识的起因。翻看我自己站点早期的关于网站架构的文章，其实没什么技术含量，无非是一些分析各个网站架构的笔记而已。最开始记录的时候我只想写给自己看。有些东西，看过了不一定理解，理解了不一定能写出来；写出来但不一定能说明白，说明白不一定让别人也明白。我只是从初级阶段做起，把看过的东西做个记录，然后通过读者的反馈再做一定的梳理，有机会的话尝试给别人讲讲，把这当成锻炼自己的一个途径。让我始料不及的是，这一类文章受到了很多读者的关注，以至于让我欢欣鼓舞，逐渐写数据库相关的内容越来越少，写Web相关技术的文章越来越多。不知不觉之间完成了又一次技术背景的转换。</p>

<p>在2008年上半年的时候，因为自己自傲莽撞，我再次犯了一次意识上的错误，而被动的导致了一次工作职责上的调整，或者说被放逐了一段时间，临时成了一个「架构师」，也变得相对清闲起来，于是有机会进行一些面向外部的技术交流，塞翁失马，我打开了另一个天地。通过这些交流，也让公司的一些真正的大牛为业界所知，引进了一些技术人才，侧面改善了一下公司在技术社区的形象，这是让我很欣慰的一件事儿。当然，这些招摇过市的事情也会引起一些误解，但是没有人做事情是能面面俱到的，不是吗？</p>

<p>这段时间终于让我的性格稍微成熟了一点。我一直是一个颇有棱角的人，有的时候会碰得一头包。性格中有些我不想改变的地方，我不会尝试改变；有些有必要改变，就必须要稍稍控制一下。很多技术人员在职场不如意，多数都是出于个人性格原因，这是我的个人感想。所以，认清自己的缺点，尝试做一些改变，终归是必要的。并不是磨平所有的棱角，有些棱角适当的藏起来吧。</p>

<p>过了一年多，我又被召回到数据库团队。作为团队的管理者，在新的岗位上有很多东西需要学，也颇有挑战。但我也越来越觉得我所想要做的不是这些事情，再过几年，也无非重复一些以前的事情，将一些业务数据做得更高，支撑能力更强而已。在这个前后，我三十而立了，我结婚了，我的人生观和价值观不可能不发生一些变化。我更想看到自己的一些想法变成现实，我喜欢把通过努力让产品尽快的改进，我热爱互联网而不喜欢金融的刻板，我喜欢社区，喜欢开源文化，喜欢 Twitter… 不过我讨厌终日繁复的会议…朋友们，你们中一定有人听过「家猪」和「野猪」的故事，我发现自己不知什么时候已经成为了一只「野猪」，再也不能变回「家猪」了。</p>

<p>支付宝现在已经发展成为了一家不折不扣的大公司。我觉得我是个幸运的人，亲身经历了一家公司从初创期到发展壮大的过程。作为一个以技术安身立命的人，在这个过程中我观察到、学习到了的东西比什么都重要，我暗自庆幸没有一味低头干活，有的时候也抬头看了一下路，这是我真正收获到的。在阿里巴巴历经五年多，深刻感受到阿里巴巴是一家了不起的企业，有独特的魅力，将来也定然会发展得更好。更令人怀念的是这里有很多优秀的同事，我从他们身上学到很多，和他们一起战斗的日子让我永生难忘。生命中非常重要的五年留在了这里。要感谢的实在太多。</p>

<p>当写这篇文章的时候，我已经在丁香园(DXY.com)工作接近半年了，我很享受创业的状态，而且，这边有更多需要直面的挑战。尽管大学专业学的不够好，但这个背景对我在丁香园的工作还是很好好处的，想来有趣，自己转了一圈居然又回到了这个领域。在做这个决定之前，自己也有过疑惑，我问自己：你有足够的管理经验么？非常遗憾，没有。不过，我还可以继续学习，还可以不断的改进自己，能够帮助团队迅速成长，我的头脑还没有完全僵化，还能够”坚持”下去，而且，和几位合作伙伴之间的协作也很顺畅。所以，我有信心接受一次新的挑战。我的新的决定也得到了妻子的支持与鼓励，我要谢谢她。</p>

<p>如同当初加入支付宝的理想主义一样，我想通过丁香园这个项目，在医疗健康领域，能够给一些人以帮助，让这个环境稍微美好一点。做这些事情，不一定会让自己功成名就，但是有可能让自己心里更加安宁一点，觉得更加踏实一点。不是每个人到这个世界上最后都会变成富有，但如果能够健康生活，能更加快乐一些，这比什么都重要。</p>

<p>或许，几年后我会写一些在丁香园的经历。</p>

<p>我是不是遗漏了什么？回头看这篇文章，我发现仍然少写了很多或许关键的内容，而我似乎潜意识中也将这个过程美化了许多，选择性的遗忘了许多，所以写得轻松了一些。在杭州这几年，因为不适应气候等诸多因素，每年都有几次很严重的关节疼痛发作，痛不欲生，你看，这只是我这十年付出的代价之一，类似的苦楚还有更多。有的时候想，如果我当初不来杭州会怎样？或者说如果我当初不选择IT会怎样？过去这十年中，我做过不少次选择，我根本不知道如果我做另一种选择的话，我现在会是什么样子。大家应该知道电影《黑客帝国》的那一幕，选择红色药丸还是蓝色药丸，所面对的世界将截然不同。</p>

<p>有的时候面对即将毕业的同学对于职业或是人生的困惑，我真的不知道该如何作答，我不知道每一次选择会怎样改变你，每一个个体是不相同的，不可能复制别人的道路，但有一点可以肯定的是，在这个糟糕的时代，我们都将面对更大的压力，会历经更大的痛苦，唯有更加顽强一些，在你快绝望的时候再坚持一下。这是我经历十年莽撞IT路后给自己的一点忠告。</p>

<p>{这是 2011 年写的东西，重新整理，放在这里作为一份记录}</p>
]]></content>
  </entry>
  
</feed>
